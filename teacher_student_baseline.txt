nohup: ignoring input
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 32, 75, 75]             864             864
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 32, 75, 75]              64              64
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 32, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 32, 75, 75]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 32, 75, 75]              64              64
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 32, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             512             512
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 96, 75, 75]           1,536           1,536
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 96, 75, 75]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 96, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 96, 38, 38]             864             864
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 96, 38, 38]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 144, 38, 38]           1,296           1,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 144, 38, 38]           1,296           1,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 24, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 144, 19, 19]           3,600           3,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 144, 19, 19]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 48, 19, 19]           6,912           6,912
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 48, 19, 19]              96              96
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 288, 19, 19]          13,824          13,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 288, 19, 19]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 288, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 288, 19, 19]           7,200           7,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 288, 19, 19]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 48, 19, 19]          13,824          13,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 48, 19, 19]              96              96
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 288, 19, 19]          13,824          13,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 288, 19, 19]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 288, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 288, 19, 19]           7,200           7,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 288, 19, 19]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 48, 19, 19]          13,824          13,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 48, 19, 19]              96              96
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 288, 19, 19]          13,824          13,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 288, 19, 19]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 288, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 288, 10, 10]           2,592           2,592
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 288, 10, 10]             576             576
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 88, 10, 10]          25,344          25,344
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 88, 10, 10]             176             176
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 528, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 528, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 528, 10, 10]           4,752           4,752
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63      [1, 88, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64      [1, 88, 10, 10]             176             176
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 528, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 528, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 528, 10, 10]           4,752           4,752
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70      [1, 88, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71      [1, 88, 10, 10]             176             176
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 528, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 528, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 528, 10, 10]           4,752           4,752
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77      [1, 88, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78      [1, 88, 10, 10]             176             176
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 528, 10, 10]          46,464          46,464
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 528, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82     [1, 528, 10, 10]          13,200          13,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83     [1, 528, 10, 10]           1,056           1,056
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84     [1, 120, 10, 10]          63,360          63,360
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85     [1, 120, 10, 10]             240             240
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86     [1, 720, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88     [1, 720, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89     [1, 720, 10, 10]          18,000          18,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91     [1, 120, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92     [1, 120, 10, 10]             240             240
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93     [1, 720, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95     [1, 720, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96     [1, 720, 10, 10]          18,000          18,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98     [1, 120, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99     [1, 120, 10, 10]             240             240
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100     [1, 720, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102     [1, 720, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103     [1, 720, 10, 10]          18,000          18,000
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105     [1, 120, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106     [1, 120, 10, 10]             240             240
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107     [1, 720, 10, 10]          86,400          86,400
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108     [1, 720, 10, 10]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109     [1, 720, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110       [1, 720, 5, 5]          18,000          18,000
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111       [1, 720, 5, 5]           1,440           1,440
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 208, 5, 5]         149,760         149,760
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 208, 5, 5]             416             416
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-114      [1, 1248, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-115      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-116      [1, 1248, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-117      [1, 1248, 5, 5]          31,200          31,200
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-118      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-119       [1, 208, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-120       [1, 208, 5, 5]             416             416
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-121      [1, 1248, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-122      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-123      [1, 1248, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-124      [1, 1248, 5, 5]          31,200          31,200
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-125      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-126       [1, 208, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-127       [1, 208, 5, 5]             416             416
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-128      [1, 1248, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-129      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-130      [1, 1248, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-131      [1, 1248, 5, 5]          31,200          31,200
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-132      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-133       [1, 208, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-134       [1, 208, 5, 5]             416             416
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-135      [1, 1248, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-136      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-137      [1, 1248, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-138      [1, 1248, 5, 5]          31,200          31,200
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-139      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-140       [1, 208, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-141       [1, 208, 5, 5]             416             416
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-142      [1, 1248, 5, 5]         259,584         259,584
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-143      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-144      [1, 1248, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-145      [1, 1248, 5, 5]          11,232          11,232
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-146      [1, 1248, 5, 5]           2,496           2,496
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-147       [1, 352, 5, 5]         439,296         439,296
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-148       [1, 352, 5, 5]             704             704
               RecycleNetwork/EfficientNetLite               Conv2d-149      [1, 1280, 5, 5]         450,560         450,560
               RecycleNetwork/EfficientNetLite          BatchNorm2d-150      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-151      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-152      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-153            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-154               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 4,817,477
Trainable params: 4,817,477
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
tensor([0.6661, 0.6211, 0.5492])
tensor([0.2871, 0.2917, 0.3310])
503
Training Started
Epoch: 1, Training Loss: 1.242310, Validation Loss: 1.132137, Training Accuracy: 0.523810, Validation Accuracy: 0.581326
Validation loss decreased (inf --> 1.132137).  Saving model ...
Epoch: 2, Training Loss: 1.008505, Validation Loss: 0.967094, Training Accuracy: 0.608715, Validation Accuracy: 0.731466
Validation loss decreased (1.132137 --> 0.967094).  Saving model ...
Epoch: 3, Training Loss: 0.879466, Validation Loss: 0.838002, Training Accuracy: 0.694491, Validation Accuracy: 0.786555
Validation loss decreased (0.967094 --> 0.838002).  Saving model ...
Epoch: 4, Training Loss: 0.787106, Validation Loss: 0.750965, Training Accuracy: 0.748833, Validation Accuracy: 0.808590
Validation loss decreased (0.838002 --> 0.750965).  Saving model ...
Epoch: 5, Training Loss: 0.723098, Validation Loss: 0.671704, Training Accuracy: 0.776346, Validation Accuracy: 0.824090
Validation loss decreased (0.750965 --> 0.671704).  Saving model ...
Epoch: 6, Training Loss: 0.664035, Validation Loss: 0.631773, Training Accuracy: 0.794522, Validation Accuracy: 0.828758
Validation loss decreased (0.671704 --> 0.631773).  Saving model ...
Epoch: 7, Training Loss: 0.616951, Validation Loss: 0.572665, Training Accuracy: 0.803859, Validation Accuracy: 0.839402
Validation loss decreased (0.631773 --> 0.572665).  Saving model ...
Epoch: 8, Training Loss: 0.577166, Validation Loss: 0.542639, Training Accuracy: 0.813321, Validation Accuracy: 0.842390
Validation loss decreased (0.572665 --> 0.542639).  Saving model ...
Epoch: 9, Training Loss: 0.538370, Validation Loss: 0.510610, Training Accuracy: 0.825023, Validation Accuracy: 0.851541
Validation loss decreased (0.542639 --> 0.510610).  Saving model ...
Epoch: 10, Training Loss: 0.516899, Validation Loss: 0.485635, Training Accuracy: 0.827700, Validation Accuracy: 0.855836
Validation loss decreased (0.510610 --> 0.485635).  Saving model ...
Epoch: 11, Training Loss: 0.490547, Validation Loss: 0.467402, Training Accuracy: 0.839340, Validation Accuracy: 0.860131
Validation loss decreased (0.485635 --> 0.467402).  Saving model ...
Epoch: 12, Training Loss: 0.467168, Validation Loss: 0.445223, Training Accuracy: 0.845440, Validation Accuracy: 0.868347
Validation loss decreased (0.467402 --> 0.445223).  Saving model ...
Epoch: 13, Training Loss: 0.447151, Validation Loss: 0.424772, Training Accuracy: 0.853470, Validation Accuracy: 0.871335
Validation loss decreased (0.445223 --> 0.424772).  Saving model ...
Epoch: 14, Training Loss: 0.429362, Validation Loss: 0.428130, Training Accuracy: 0.854902, Validation Accuracy: 0.875630
EarlyStopping counter: 1 out of 10
Epoch: 15, Training Loss: 0.420024, Validation Loss: 0.398108, Training Accuracy: 0.861251, Validation Accuracy: 0.882540
Validation loss decreased (0.424772 --> 0.398108).  Saving model ...
Epoch: 16, Training Loss: 0.406606, Validation Loss: 0.382375, Training Accuracy: 0.865173, Validation Accuracy: 0.888329
Validation loss decreased (0.398108 --> 0.382375).  Saving model ...
Epoch: 17, Training Loss: 0.391667, Validation Loss: 0.386087, Training Accuracy: 0.869841, Validation Accuracy: 0.886835
EarlyStopping counter: 1 out of 10
Epoch: 18, Training Loss: 0.386238, Validation Loss: 0.364242, Training Accuracy: 0.873887, Validation Accuracy: 0.893557
Validation loss decreased (0.382375 --> 0.364242).  Saving model ...
Epoch: 19, Training Loss: 0.374114, Validation Loss: 0.359035, Training Accuracy: 0.878120, Validation Accuracy: 0.892624
Validation loss decreased (0.364242 --> 0.359035).  Saving model ...
Epoch: 20, Training Loss: 0.368279, Validation Loss: 0.358540, Training Accuracy: 0.879988, Validation Accuracy: 0.893557
Validation loss decreased (0.359035 --> 0.358540).  Saving model ...
Epoch: 21, Training Loss: 0.359273, Validation Loss: 0.364014, Training Accuracy: 0.883536, Validation Accuracy: 0.892250
EarlyStopping counter: 1 out of 10
Epoch: 22, Training Loss: 0.347151, Validation Loss: 0.341065, Training Accuracy: 0.886212, Validation Accuracy: 0.900654
Validation loss decreased (0.358540 --> 0.341065).  Saving model ...
Epoch: 23, Training Loss: 0.342831, Validation Loss: 0.336834, Training Accuracy: 0.888142, Validation Accuracy: 0.901961
Validation loss decreased (0.341065 --> 0.336834).  Saving model ...
Epoch: 24, Training Loss: 0.331178, Validation Loss: 0.320497, Training Accuracy: 0.895114, Validation Accuracy: 0.906256
Validation loss decreased (0.336834 --> 0.320497).  Saving model ...
Epoch: 25, Training Loss: 0.327317, Validation Loss: 0.307851, Training Accuracy: 0.897603, Validation Accuracy: 0.910551
Validation loss decreased (0.320497 --> 0.307851).  Saving model ...
Epoch: 26, Training Loss: 0.316554, Validation Loss: 0.301246, Training Accuracy: 0.899222, Validation Accuracy: 0.912418
Validation loss decreased (0.307851 --> 0.301246).  Saving model ...
Epoch: 27, Training Loss: 0.306856, Validation Loss: 0.311374, Training Accuracy: 0.902459, Validation Accuracy: 0.910551
EarlyStopping counter: 1 out of 10
Epoch: 28, Training Loss: 0.297354, Validation Loss: 0.295494, Training Accuracy: 0.906629, Validation Accuracy: 0.913725
Validation loss decreased (0.301246 --> 0.295494).  Saving model ...
Epoch: 29, Training Loss: 0.293862, Validation Loss: 0.309923, Training Accuracy: 0.907439, Validation Accuracy: 0.909991
EarlyStopping counter: 1 out of 10
Epoch: 30, Training Loss: 0.295582, Validation Loss: 0.290648, Training Accuracy: 0.909742, Validation Accuracy: 0.917647
Validation loss decreased (0.295494 --> 0.290648).  Saving model ...
Epoch: 31, Training Loss: 0.284810, Validation Loss: 0.286425, Training Accuracy: 0.913788, Validation Accuracy: 0.917834
Validation loss decreased (0.290648 --> 0.286425).  Saving model ...
Epoch: 32, Training Loss: 0.281066, Validation Loss: 0.283342, Training Accuracy: 0.914659, Validation Accuracy: 0.917087
Validation loss decreased (0.286425 --> 0.283342).  Saving model ...
Epoch: 33, Training Loss: 0.278422, Validation Loss: 0.289317, Training Accuracy: 0.911298, Validation Accuracy: 0.917087
EarlyStopping counter: 1 out of 10
Epoch: 34, Training Loss: 0.264502, Validation Loss: 0.284533, Training Accuracy: 0.920448, Validation Accuracy: 0.917087
EarlyStopping counter: 2 out of 10
Epoch: 35, Training Loss: 0.257590, Validation Loss: 0.262468, Training Accuracy: 0.921195, Validation Accuracy: 0.923436
Validation loss decreased (0.283342 --> 0.262468).  Saving model ...
Epoch: 36, Training Loss: 0.256493, Validation Loss: 0.285821, Training Accuracy: 0.922502, Validation Accuracy: 0.918021
EarlyStopping counter: 1 out of 10
Epoch: 37, Training Loss: 0.258298, Validation Loss: 0.261369, Training Accuracy: 0.924370, Validation Accuracy: 0.923810
Validation loss decreased (0.262468 --> 0.261369).  Saving model ...
Epoch: 38, Training Loss: 0.242811, Validation Loss: 0.258639, Training Accuracy: 0.925801, Validation Accuracy: 0.925677
Validation loss decreased (0.261369 --> 0.258639).  Saving model ...
Epoch: 39, Training Loss: 0.244223, Validation Loss: 0.277938, Training Accuracy: 0.927793, Validation Accuracy: 0.921008
Epoch 00039: reducing learning rate of group 0 to 1.0000e-05.
EarlyStopping counter: 1 out of 10
Epoch: 40, Training Loss: 0.228109, Validation Loss: 0.220020, Training Accuracy: 0.931777, Validation Accuracy: 0.932960
Validation loss decreased (0.258639 --> 0.220020).  Saving model ...
Epoch: 41, Training Loss: 0.237192, Validation Loss: 0.218339, Training Accuracy: 0.929350, Validation Accuracy: 0.932773
Validation loss decreased (0.220020 --> 0.218339).  Saving model ...
Epoch: 42, Training Loss: 0.229868, Validation Loss: 0.219249, Training Accuracy: 0.931777, Validation Accuracy: 0.932026
EarlyStopping counter: 1 out of 10
Epoch: 43, Training Loss: 0.237320, Validation Loss: 0.218872, Training Accuracy: 0.928540, Validation Accuracy: 0.932773
EarlyStopping counter: 2 out of 10
Epoch: 44, Training Loss: 0.232859, Validation Loss: 0.217172, Training Accuracy: 0.930532, Validation Accuracy: 0.933333
Epoch 00044: reducing learning rate of group 0 to 1.0000e-06.
Validation loss decreased (0.218339 --> 0.217172).  Saving model ...
Epoch: 45, Training Loss: 0.232645, Validation Loss: 0.215240, Training Accuracy: 0.931279, Validation Accuracy: 0.933707
Validation loss decreased (0.217172 --> 0.215240).  Saving model ...
Epoch: 46, Training Loss: 0.231872, Validation Loss: 0.213133, Training Accuracy: 0.929599, Validation Accuracy: 0.934267
Validation loss decreased (0.215240 --> 0.213133).  Saving model ...
Epoch: 47, Training Loss: 0.229276, Validation Loss: 0.215584, Training Accuracy: 0.932213, Validation Accuracy: 0.934827
EarlyStopping counter: 1 out of 10
Epoch: 48, Training Loss: 0.231439, Validation Loss: 0.213829, Training Accuracy: 0.931279, Validation Accuracy: 0.935201
Epoch 00048: reducing learning rate of group 0 to 1.0000e-07.
EarlyStopping counter: 2 out of 10
Epoch: 49, Training Loss: 0.231259, Validation Loss: 0.214675, Training Accuracy: 0.930906, Validation Accuracy: 0.933520
EarlyStopping counter: 3 out of 10
Epoch: 50, Training Loss: 0.225562, Validation Loss: 0.213217, Training Accuracy: 0.933022, Validation Accuracy: 0.933894
EarlyStopping counter: 4 out of 10
Epoch: 51, Training Loss: 0.233055, Validation Loss: 0.215358, Training Accuracy: 0.932213, Validation Accuracy: 0.934080
EarlyStopping counter: 5 out of 10
Epoch: 52, Training Loss: 0.232155, Validation Loss: 0.214550, Training Accuracy: 0.931653, Validation Accuracy: 0.933520
Epoch 00052: reducing learning rate of group 0 to 1.0000e-08.
EarlyStopping counter: 6 out of 10
Epoch: 53, Training Loss: 0.230698, Validation Loss: 0.212637, Training Accuracy: 0.932898, Validation Accuracy: 0.934080
Validation loss decreased (0.213133 --> 0.212637).  Saving model ...
Epoch: 54, Training Loss: 0.230362, Validation Loss: 0.214656, Training Accuracy: 0.931217, Validation Accuracy: 0.933707
EarlyStopping counter: 1 out of 10
Epoch: 55, Training Loss: 0.229829, Validation Loss: 0.215485, Training Accuracy: 0.930906, Validation Accuracy: 0.932960
EarlyStopping counter: 2 out of 10
Epoch: 56, Training Loss: 0.235391, Validation Loss: 0.213837, Training Accuracy: 0.931341, Validation Accuracy: 0.934641
EarlyStopping counter: 3 out of 10
Epoch: 57, Training Loss: 0.231167, Validation Loss: 0.213262, Training Accuracy: 0.932337, Validation Accuracy: 0.933520
EarlyStopping counter: 4 out of 10
Epoch: 58, Training Loss: 0.236248, Validation Loss: 0.213442, Training Accuracy: 0.930594, Validation Accuracy: 0.934080
EarlyStopping counter: 5 out of 10
Epoch: 59, Training Loss: 0.234878, Validation Loss: 0.214174, Training Accuracy: 0.931155, Validation Accuracy: 0.934267
EarlyStopping counter: 6 out of 10
Epoch: 60, Training Loss: 0.234242, Validation Loss: 0.213772, Training Accuracy: 0.929350, Validation Accuracy: 0.934641
EarlyStopping counter: 7 out of 10
Epoch: 61, Training Loss: 0.226821, Validation Loss: 0.213467, Training Accuracy: 0.933769, Validation Accuracy: 0.934080
EarlyStopping counter: 8 out of 10
Epoch: 62, Training Loss: 0.228747, Validation Loss: 0.215550, Training Accuracy: 0.933022, Validation Accuracy: 0.934080
EarlyStopping counter: 9 out of 10
Epoch: 63, Training Loss: 0.231037, Validation Loss: 0.213506, Training Accuracy: 0.931092, Validation Accuracy: 0.934454
EarlyStopping counter: 10 out of 10
Early Stopping at Epoch: 63
Test Loss: 0.208809, Test Accuracy: 0.9331
