----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 32, 75, 75]             864             864
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 32, 75, 75]              64              64
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 32, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 32, 75, 75]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 32, 75, 75]              64              64
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 32, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             512             512
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 96, 75, 75]           1,536           1,536
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 96, 75, 75]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 96, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 96, 38, 38]             864             864
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 96, 38, 38]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 144, 38, 38]           1,296           1,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 144, 19, 19]           3,600           3,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 144, 19, 19]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,760           5,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 240, 19, 19]           6,000           6,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,377,413
Trainable params: 3,377,413
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
17
tensor([2, 2, 0, 3, 2, 3, 0, 2, 2, 2, 2, 2, 1, 2, 3, 2, 0, 0, 2, 2, 4, 2, 2, 2,
        2, 3, 4, 2, 2, 2, 2, 4])
tensor([4, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 3, 1, 3, 2, 2, 4, 4,
        2, 2, 0, 2, 4, 3, 3, 2])
tensor([4, 2, 0, 2, 2, 2, 2, 3, 2, 3, 3, 1, 1, 1, 2, 1, 4, 1, 2, 4, 2, 2, 2, 2,
        2, 3, 4, 2, 1, 2, 4, 2])
tensor([1, 2, 4, 2, 2, 2, 2, 2, 2, 3, 1, 0, 2, 4, 2, 2, 4, 4, 4, 4, 0, 0, 2, 2,
        4, 2, 2, 2, 2, 2, 2, 0])
tensor([2, 2, 4, 2, 2, 2, 2, 1, 0, 1, 4, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 0, 4, 2,
        2, 2, 2, 2, 2, 3, 0, 2])
tensor([4, 1, 3, 2, 2, 4, 3, 2, 0, 2, 2, 4, 2, 3, 0, 4, 3, 3, 3, 2, 2, 3, 3, 3,
        4, 2, 1, 4, 2, 2, 0, 2])
tensor([4, 2, 2, 3, 2, 2, 2, 3, 2, 2, 4, 3, 2, 0, 3, 2, 2, 2, 4, 1, 2, 2, 1, 2,
        2, 2, 2, 2, 0, 2, 2, 2])
tensor([2, 2, 1, 4, 1, 2, 3, 1, 4, 2, 3, 2, 2, 2, 4, 4, 2, 0, 2, 2, 1, 0, 4, 2,
        3, 4, 4, 1, 3, 2, 3, 2])
tensor([4, 2, 3, 2, 3, 2, 2, 3, 0, 2, 3, 2, 1, 2, 0, 1, 4, 0, 2, 2, 1, 4, 2, 4,
        4, 4, 1, 4, 0, 2, 2, 2])
tensor([2, 2, 4, 2, 3, 2, 4, 2, 2, 2, 0, 0, 2, 2, 2, 1, 1, 4, 4, 4, 4, 2, 2, 2,
        2, 1, 1, 1, 4, 2, 2, 4])
tensor([2, 2, 2, 4, 0, 1, 2, 3, 4, 2, 4, 2, 0, 2, 2, 2, 3, 2, 4, 3, 2, 2, 2, 2,
        2, 2, 0, 2, 2, 2, 3, 3])
tensor([3, 2, 3, 2, 2, 4, 1, 0, 2, 4, 0, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 4, 2, 0,
        0, 2, 2, 2, 4, 2, 0, 2])
tensor([2, 3, 2, 3, 2, 1, 2, 2, 1, 1, 3, 3, 2, 2, 0, 2, 4, 2, 4, 2, 2, 4, 0, 4,
        2, 2, 4, 2, 2, 3, 4, 2])
tensor([2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 0, 2, 2, 1, 2, 3, 3, 3, 2, 2, 3, 4, 2,
        0, 2, 2, 0, 2, 3, 3, 3])
tensor([2, 0, 2, 4, 4, 1, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 4, 2, 2, 0,
        2, 2, 3, 2, 4, 4, 2, 2])
tensor([2, 2, 4, 2, 0, 4, 2, 2, 2, 1, 2, 1, 1, 2, 3, 1, 2, 4, 3, 3, 2, 1, 3, 4,
        2, 0, 2, 1, 2, 3, 0, 2])
tensor([1, 1, 0, 4, 3, 4, 2, 4, 4, 2, 2, 1, 2, 4, 4, 2, 0, 2, 2, 3, 2, 4, 2])
backbone.stem.0
5

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.stem.0 (Conv2d(3, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on backbone.stem.0 (Conv2d(3, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), #idxs=5
[1] prune_out_channels on backbone.stem.0 (Conv2d(3, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on backbone.stem.1 (BatchNorm2d(27, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=5
[2] prune_out_channels on backbone.stem.1 (BatchNorm2d(27, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_26(HardtanhBackward0), #idxs=5
[3] prune_out_channels on _ElementWiseOp_26(HardtanhBackward0) => prune_out_channels on backbone.blocks.0.0._depthwise_conv (Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=27, bias=False)), #idxs=5
[4] prune_out_channels on backbone.blocks.0.0._depthwise_conv (Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=27, bias=False)) => prune_out_channels on backbone.blocks.0.0._bn1 (BatchNorm2d(27, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=5
[5] prune_out_channels on backbone.blocks.0.0._bn1 (BatchNorm2d(27, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_25(HardtanhBackward0), #idxs=5
[6] prune_out_channels on _ElementWiseOp_25(HardtanhBackward0) => prune_in_channels on backbone.blocks.0.0._project_conv (Conv2d(27, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=5
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.stem.0
48
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True, False])
torch.Size([32])
torch.Size([27])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.0.0._depthwise_conv
47
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True, False])
torch.Size([32])
torch.Size([27])
backbone.blocks.0.0._depthwise_conv
0
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.0.0._depthwise_conv (Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=27, bias=False)) => prune_out_channels on backbone.blocks.0.0._depthwise_conv (Conv2d(27, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=27, bias=False)), #idxs=0
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.0.0._depthwise_conv
47
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True])
torch.Size([27])
torch.Size([27])
backbone.blocks.0.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.0.0._project_conv (Conv2d(27, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.0.0._project_conv (Conv2d(27, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.0.0._project_conv
46
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([16])
torch.Size([16])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 96, 75, 75]           1,536           1,536
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 96, 75, 75]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 96, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 96, 38, 38]             864             864
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 96, 38, 38]             192             192
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 144, 38, 38]           1,296           1,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 144, 19, 19]           3,600           3,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 144, 19, 19]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,760           5,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 240, 19, 19]           6,000           6,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,377,133
Trainable params: 3,377,133
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.1.0._expand_conv
7

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.0._expand_conv (Conv2d(16, 89, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.0._expand_conv (Conv2d(16, 89, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=7
[1] prune_out_channels on backbone.blocks.1.0._expand_conv (Conv2d(16, 89, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.0._bn0 (BatchNorm2d(89, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=7
[2] prune_out_channels on backbone.blocks.1.0._bn0 (BatchNorm2d(89, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_24(HardtanhBackward0), #idxs=7
[3] prune_out_channels on _ElementWiseOp_24(HardtanhBackward0) => prune_out_channels on backbone.blocks.1.0._depthwise_conv (Conv2d(89, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=89, bias=False)), #idxs=7
[4] prune_out_channels on backbone.blocks.1.0._depthwise_conv (Conv2d(89, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=89, bias=False)) => prune_out_channels on backbone.blocks.1.0._bn1 (BatchNorm2d(89, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=7
[5] prune_out_channels on backbone.blocks.1.0._bn1 (BatchNorm2d(89, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_23(HardtanhBackward0), #idxs=7
[6] prune_out_channels on _ElementWiseOp_23(HardtanhBackward0) => prune_in_channels on backbone.blocks.1.0._project_conv (Conv2d(89, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=7
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.1.0._expand_conv
45
tensor([ True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True])
torch.Size([96])
torch.Size([89])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.1.0._depthwise_conv
44
tensor([ True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True])
torch.Size([96])
torch.Size([89])
backbone.blocks.1.0._depthwise_conv
0
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.0._depthwise_conv (Conv2d(89, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=89, bias=False)) => prune_out_channels on backbone.blocks.1.0._depthwise_conv (Conv2d(89, 89, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=89, bias=False)), #idxs=0
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.1.0._depthwise_conv
44
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True])
torch.Size([89])
torch.Size([89])
backbone.blocks.1.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.0._project_conv (Conv2d(89, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.0._project_conv (Conv2d(89, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.1.0._project_conv
43
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([24])
torch.Size([24])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 144, 38, 38]           1,296           1,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 144, 19, 19]           3,600           3,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 144, 19, 19]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,760           5,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 240, 19, 19]           6,000           6,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,376,762
Trainable params: 3,376,762
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.1.1._expand_conv
6

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.1._expand_conv (Conv2d(24, 138, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.1._expand_conv (Conv2d(24, 138, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=6
[1] prune_out_channels on backbone.blocks.1.1._expand_conv (Conv2d(24, 138, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.1._bn0 (BatchNorm2d(138, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=6
[2] prune_out_channels on backbone.blocks.1.1._bn0 (BatchNorm2d(138, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_28(HardtanhBackward0), #idxs=6
[3] prune_out_channels on _ElementWiseOp_28(HardtanhBackward0) => prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(138, 138, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=138, bias=False)), #idxs=6
[4] prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(138, 138, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=138, bias=False)) => prune_out_channels on backbone.blocks.1.1._bn1 (BatchNorm2d(138, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=6
[5] prune_out_channels on backbone.blocks.1.1._bn1 (BatchNorm2d(138, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_27(HardtanhBackward0), #idxs=6
[6] prune_out_channels on _ElementWiseOp_27(HardtanhBackward0) => prune_in_channels on backbone.blocks.1.1._project_conv (Conv2d(138, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=6
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.1.1._expand_conv
42
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([144])
torch.Size([138])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.1.1._depthwise_conv
41
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([144])
torch.Size([138])
backbone.blocks.1.1._depthwise_conv
9
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=129, bias=False)) => prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=129, bias=False)), #idxs=9
[1] prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=129, bias=False)) => prune_out_channels on _ElementWiseOp_28(HardtanhBackward0), #idxs=9
[2] prune_out_channels on backbone.blocks.1.1._depthwise_conv (Conv2d(129, 129, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=129, bias=False)) => prune_out_channels on backbone.blocks.1.1._bn1 (BatchNorm2d(129, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[3] prune_out_channels on backbone.blocks.1.1._bn1 (BatchNorm2d(129, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_27(HardtanhBackward0), #idxs=9
[4] prune_out_channels on _ElementWiseOp_27(HardtanhBackward0) => prune_in_channels on backbone.blocks.1.1._project_conv (Conv2d(129, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
[5] prune_out_channels on _ElementWiseOp_28(HardtanhBackward0) => prune_out_channels on backbone.blocks.1.1._bn0 (BatchNorm2d(129, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[6] prune_out_channels on backbone.blocks.1.1._bn0 (BatchNorm2d(129, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.1.1._expand_conv (Conv2d(24, 129, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.1.1._depthwise_conv
41
tensor([False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([138])
torch.Size([129])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.1.1._expand_conv
42
tensor([False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([138])
torch.Size([129])
backbone.blocks.1.1._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.1.1._project_conv (Conv2d(129, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.1.1._project_conv (Conv2d(129, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.1.1._project_conv
40
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([24])
torch.Size([24])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 144, 38, 38]           3,456           3,456
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 144, 38, 38]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 144, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 144, 19, 19]           3,600           3,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 144, 19, 19]             288             288
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,760           5,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 240, 19, 19]           6,000           6,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,375,847
Trainable params: 3,375,847
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.2.0._expand_conv
5

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.0._expand_conv (Conv2d(24, 139, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.0._expand_conv (Conv2d(24, 139, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=5
[1] prune_out_channels on backbone.blocks.2.0._expand_conv (Conv2d(24, 139, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.0._bn0 (BatchNorm2d(139, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=5
[2] prune_out_channels on backbone.blocks.2.0._bn0 (BatchNorm2d(139, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_21(HardtanhBackward0), #idxs=5
[3] prune_out_channels on _ElementWiseOp_21(HardtanhBackward0) => prune_out_channels on backbone.blocks.2.0._depthwise_conv (Conv2d(139, 139, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=139, bias=False)), #idxs=5
[4] prune_out_channels on backbone.blocks.2.0._depthwise_conv (Conv2d(139, 139, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=139, bias=False)) => prune_out_channels on backbone.blocks.2.0._bn1 (BatchNorm2d(139, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=5
[5] prune_out_channels on backbone.blocks.2.0._bn1 (BatchNorm2d(139, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_20(HardtanhBackward0), #idxs=5
[6] prune_out_channels on _ElementWiseOp_20(HardtanhBackward0) => prune_in_channels on backbone.blocks.2.0._project_conv (Conv2d(139, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=5
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.2.0._expand_conv
39
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([144])
torch.Size([139])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.2.0._depthwise_conv
38
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([144])
torch.Size([139])
backbone.blocks.2.0._depthwise_conv
0
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.0._depthwise_conv (Conv2d(139, 139, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=139, bias=False)) => prune_out_channels on backbone.blocks.2.0._depthwise_conv (Conv2d(139, 139, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=139, bias=False)), #idxs=0
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.2.0._depthwise_conv
38
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True])
torch.Size([139])
torch.Size([139])
backbone.blocks.2.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.0._project_conv (Conv2d(139, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.0._project_conv (Conv2d(139, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.2.0._project_conv
37
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([40])
torch.Size([40])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 240, 19, 19]           6,000           6,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,375,382
Trainable params: 3,375,382
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.2.1._expand_conv
9

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.1._expand_conv (Conv2d(40, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.1._expand_conv (Conv2d(40, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
[1] prune_out_channels on backbone.blocks.2.1._expand_conv (Conv2d(40, 231, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.1._bn0 (BatchNorm2d(231, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[2] prune_out_channels on backbone.blocks.2.1._bn0 (BatchNorm2d(231, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_30(HardtanhBackward0), #idxs=9
[3] prune_out_channels on _ElementWiseOp_30(HardtanhBackward0) => prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(231, 231, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=231, bias=False)), #idxs=9
[4] prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(231, 231, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=231, bias=False)) => prune_out_channels on backbone.blocks.2.1._bn1 (BatchNorm2d(231, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[5] prune_out_channels on backbone.blocks.2.1._bn1 (BatchNorm2d(231, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_29(HardtanhBackward0), #idxs=9
[6] prune_out_channels on _ElementWiseOp_29(HardtanhBackward0) => prune_in_channels on backbone.blocks.2.1._project_conv (Conv2d(231, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.2.1._expand_conv
36
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True])
torch.Size([240])
torch.Size([231])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.2.1._depthwise_conv
35
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True])
torch.Size([240])
torch.Size([231])
backbone.blocks.2.1._depthwise_conv
30
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(201, 201, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=201, bias=False)) => prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(201, 201, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=201, bias=False)), #idxs=30
[1] prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(201, 201, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=201, bias=False)) => prune_out_channels on _ElementWiseOp_30(HardtanhBackward0), #idxs=30
[2] prune_out_channels on backbone.blocks.2.1._depthwise_conv (Conv2d(201, 201, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=201, bias=False)) => prune_out_channels on backbone.blocks.2.1._bn1 (BatchNorm2d(201, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=30
[3] prune_out_channels on backbone.blocks.2.1._bn1 (BatchNorm2d(201, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_29(HardtanhBackward0), #idxs=30
[4] prune_out_channels on _ElementWiseOp_29(HardtanhBackward0) => prune_in_channels on backbone.blocks.2.1._project_conv (Conv2d(201, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=30
[5] prune_out_channels on _ElementWiseOp_30(HardtanhBackward0) => prune_out_channels on backbone.blocks.2.1._bn0 (BatchNorm2d(201, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=30
[6] prune_out_channels on backbone.blocks.2.1._bn0 (BatchNorm2d(201, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.2.1._expand_conv (Conv2d(40, 201, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=30
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.2.1._depthwise_conv
35
tensor([ True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True])
torch.Size([231])
torch.Size([201])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.2.1._expand_conv
36
tensor([ True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True])
torch.Size([231])
torch.Size([201])
backbone.blocks.2.1._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.2.1._project_conv (Conv2d(201, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.2.1._project_conv (Conv2d(201, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.2.1._project_conv
34
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([40])
torch.Size([40])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 240, 19, 19]           9,600           9,600
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 240, 19, 19]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 240, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 240, 10, 10]           2,160           2,160
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 240, 10, 10]             480             480
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          19,200          19,200
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,371,131
Trainable params: 3,371,131
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.3.0._expand_conv
7

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.0._expand_conv (Conv2d(40, 233, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.0._expand_conv (Conv2d(40, 233, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=7
[1] prune_out_channels on backbone.blocks.3.0._expand_conv (Conv2d(40, 233, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.0._bn0 (BatchNorm2d(233, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=7
[2] prune_out_channels on backbone.blocks.3.0._bn0 (BatchNorm2d(233, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_18(HardtanhBackward0), #idxs=7
[3] prune_out_channels on _ElementWiseOp_18(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(233, 233, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=233, bias=False)), #idxs=7
[4] prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(233, 233, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=233, bias=False)) => prune_out_channels on backbone.blocks.3.0._bn1 (BatchNorm2d(233, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=7
[5] prune_out_channels on backbone.blocks.3.0._bn1 (BatchNorm2d(233, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_17(HardtanhBackward0), #idxs=7
[6] prune_out_channels on _ElementWiseOp_17(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.0._project_conv (Conv2d(233, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=7
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.0._expand_conv
33
tensor([ True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([240])
torch.Size([233])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.0._depthwise_conv
32
tensor([ True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([240])
torch.Size([233])
backbone.blocks.3.0._depthwise_conv
1
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)) => prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)), #idxs=1
[1] prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)) => prune_out_channels on _ElementWiseOp_18(HardtanhBackward0), #idxs=1
[2] prune_out_channels on backbone.blocks.3.0._depthwise_conv (Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)) => prune_out_channels on backbone.blocks.3.0._bn1 (BatchNorm2d(232, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=1
[3] prune_out_channels on backbone.blocks.3.0._bn1 (BatchNorm2d(232, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_17(HardtanhBackward0), #idxs=1
[4] prune_out_channels on _ElementWiseOp_17(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.0._project_conv (Conv2d(232, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=1
[5] prune_out_channels on _ElementWiseOp_18(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.0._bn0 (BatchNorm2d(232, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=1
[6] prune_out_channels on backbone.blocks.3.0._bn0 (BatchNorm2d(232, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.3.0._expand_conv (Conv2d(40, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=1
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.0._depthwise_conv
32
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True])
torch.Size([233])
torch.Size([232])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.0._expand_conv
33
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True])
torch.Size([233])
torch.Size([232])
backbone.blocks.3.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.0._project_conv (Conv2d(232, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.0._project_conv (Conv2d(232, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.0._project_conv
31
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True])
torch.Size([80])
torch.Size([80])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,370,067
Trainable params: 3,370,067
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.3.1._expand_conv
28

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.1._expand_conv (Conv2d(80, 452, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.1._expand_conv (Conv2d(80, 452, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=28
[1] prune_out_channels on backbone.blocks.3.1._expand_conv (Conv2d(80, 452, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.1._bn0 (BatchNorm2d(452, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=28
[2] prune_out_channels on backbone.blocks.3.1._bn0 (BatchNorm2d(452, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_32(HardtanhBackward0), #idxs=28
[3] prune_out_channels on _ElementWiseOp_32(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(452, 452, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=452, bias=False)), #idxs=28
[4] prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(452, 452, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=452, bias=False)) => prune_out_channels on backbone.blocks.3.1._bn1 (BatchNorm2d(452, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=28
[5] prune_out_channels on backbone.blocks.3.1._bn1 (BatchNorm2d(452, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_31(HardtanhBackward0), #idxs=28
[6] prune_out_channels on _ElementWiseOp_31(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.1._project_conv (Conv2d(452, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=28
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.1._expand_conv
30
tensor([ True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([452])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.1._depthwise_conv
29
tensor([ True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([452])
backbone.blocks.3.1._depthwise_conv
89
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(363, 363, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=363, bias=False)) => prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(363, 363, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=363, bias=False)), #idxs=89
[1] prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(363, 363, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=363, bias=False)) => prune_out_channels on _ElementWiseOp_32(HardtanhBackward0), #idxs=89
[2] prune_out_channels on backbone.blocks.3.1._depthwise_conv (Conv2d(363, 363, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=363, bias=False)) => prune_out_channels on backbone.blocks.3.1._bn1 (BatchNorm2d(363, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=89
[3] prune_out_channels on backbone.blocks.3.1._bn1 (BatchNorm2d(363, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_31(HardtanhBackward0), #idxs=89
[4] prune_out_channels on _ElementWiseOp_31(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.1._project_conv (Conv2d(363, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=89
[5] prune_out_channels on _ElementWiseOp_32(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.1._bn0 (BatchNorm2d(363, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=89
[6] prune_out_channels on backbone.blocks.3.1._bn0 (BatchNorm2d(363, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.3.1._expand_conv (Conv2d(80, 363, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=89
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.1._depthwise_conv
29
tensor([False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True, False,  True,  True, False, False,  True, False,
         True,  True,  True, False,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True, False,  True,  True, False,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True, False,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True, False,  True,  True,  True,
        False,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True, False, False,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False, False,  True, False,
         True,  True])
torch.Size([452])
torch.Size([363])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.1._expand_conv
30
tensor([False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True, False,  True,  True, False, False,  True, False,
         True,  True,  True, False,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True, False,  True,  True, False,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True, False,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True, False,  True,  True,  True,
        False,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True, False, False,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False, False,  True, False,
         True,  True])
torch.Size([452])
torch.Size([363])
backbone.blocks.3.1._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.1._project_conv (Conv2d(363, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.1._project_conv (Conv2d(363, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.1._project_conv
28
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True])
torch.Size([80])
torch.Size([80])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 480, 10, 10]           4,320           4,320
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,349,826
Trainable params: 3,349,826
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.3.2._expand_conv
25

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.2._expand_conv (Conv2d(80, 455, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.2._expand_conv (Conv2d(80, 455, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=25
[1] prune_out_channels on backbone.blocks.3.2._expand_conv (Conv2d(80, 455, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.2._bn0 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=25
[2] prune_out_channels on backbone.blocks.3.2._bn0 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_34(HardtanhBackward0), #idxs=25
[3] prune_out_channels on _ElementWiseOp_34(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(455, 455, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=455, bias=False)), #idxs=25
[4] prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(455, 455, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=455, bias=False)) => prune_out_channels on backbone.blocks.3.2._bn1 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=25
[5] prune_out_channels on backbone.blocks.3.2._bn1 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_33(HardtanhBackward0), #idxs=25
[6] prune_out_channels on _ElementWiseOp_33(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.2._project_conv (Conv2d(455, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=25
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.2._expand_conv
27
tensor([ True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([455])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.2._depthwise_conv
26
tensor([ True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([455])
backbone.blocks.3.2._depthwise_conv
122
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(333, 333, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=333, bias=False)) => prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(333, 333, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=333, bias=False)), #idxs=122
[1] prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(333, 333, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=333, bias=False)) => prune_out_channels on _ElementWiseOp_34(HardtanhBackward0), #idxs=122
[2] prune_out_channels on backbone.blocks.3.2._depthwise_conv (Conv2d(333, 333, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=333, bias=False)) => prune_out_channels on backbone.blocks.3.2._bn1 (BatchNorm2d(333, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=122
[3] prune_out_channels on backbone.blocks.3.2._bn1 (BatchNorm2d(333, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_33(HardtanhBackward0), #idxs=122
[4] prune_out_channels on _ElementWiseOp_33(HardtanhBackward0) => prune_in_channels on backbone.blocks.3.2._project_conv (Conv2d(333, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=122
[5] prune_out_channels on _ElementWiseOp_34(HardtanhBackward0) => prune_out_channels on backbone.blocks.3.2._bn0 (BatchNorm2d(333, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=122
[6] prune_out_channels on backbone.blocks.3.2._bn0 (BatchNorm2d(333, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.3.2._expand_conv (Conv2d(80, 333, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=122
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.3.2._depthwise_conv
26
tensor([ True,  True,  True,  True, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True,  True, False, False,  True,
         True,  True,  True,  True, False,  True, False,  True, False, False,
         True,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True, False, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
        False, False,  True,  True, False,  True,  True, False,  True, False,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True,  True,  True,  True, False,
        False,  True,  True, False, False, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True,  True, False,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
         True,  True, False,  True, False, False,  True, False, False, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True, False, False,
         True,  True, False, False, False, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True, False, False, False,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True, False, False, False,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False, False,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
        False,  True, False,  True, False])
torch.Size([455])
torch.Size([333])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.2._expand_conv
27
tensor([ True,  True,  True,  True, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True,  True, False, False,  True,
         True,  True,  True,  True, False,  True, False,  True, False, False,
         True,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True, False, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
        False, False,  True,  True, False,  True,  True, False,  True, False,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True,  True,  True,  True, False,
        False,  True,  True, False, False, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True,  True, False,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
         True,  True, False,  True, False, False,  True, False, False, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True, False, False,
         True,  True, False, False, False, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True, False, False, False,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True, False, False, False,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False, False,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
        False,  True, False,  True, False])
torch.Size([455])
torch.Size([333])
backbone.blocks.3.2._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.3.2._project_conv (Conv2d(333, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.3.2._project_conv (Conv2d(333, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.3.2._project_conv
25
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True])
torch.Size([80])
torch.Size([80])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 480, 10, 10]          38,400          38,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 480, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 480, 10, 10]          12,000          12,000
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 480, 10, 10]             960             960
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          53,760          53,760
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,324,395
Trainable params: 3,324,395
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.4.0._expand_conv
9

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.0._expand_conv (Conv2d(80, 471, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.0._expand_conv (Conv2d(80, 471, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
[1] prune_out_channels on backbone.blocks.4.0._expand_conv (Conv2d(80, 471, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.0._bn0 (BatchNorm2d(471, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[2] prune_out_channels on backbone.blocks.4.0._bn0 (BatchNorm2d(471, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_14(HardtanhBackward0), #idxs=9
[3] prune_out_channels on _ElementWiseOp_14(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(471, 471, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=471, bias=False)), #idxs=9
[4] prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(471, 471, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=471, bias=False)) => prune_out_channels on backbone.blocks.4.0._bn1 (BatchNorm2d(471, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[5] prune_out_channels on backbone.blocks.4.0._bn1 (BatchNorm2d(471, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_13(HardtanhBackward0), #idxs=9
[6] prune_out_channels on _ElementWiseOp_13(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.0._project_conv (Conv2d(471, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.0._expand_conv
24
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([471])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.0._depthwise_conv
23
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])
torch.Size([480])
torch.Size([471])
backbone.blocks.4.0._depthwise_conv
16
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(455, 455, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=455, bias=False)) => prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(455, 455, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=455, bias=False)), #idxs=16
[1] prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(455, 455, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=455, bias=False)) => prune_out_channels on _ElementWiseOp_14(HardtanhBackward0), #idxs=16
[2] prune_out_channels on backbone.blocks.4.0._depthwise_conv (Conv2d(455, 455, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=455, bias=False)) => prune_out_channels on backbone.blocks.4.0._bn1 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=16
[3] prune_out_channels on backbone.blocks.4.0._bn1 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_13(HardtanhBackward0), #idxs=16
[4] prune_out_channels on _ElementWiseOp_13(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.0._project_conv (Conv2d(455, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=16
[5] prune_out_channels on _ElementWiseOp_14(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.0._bn0 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=16
[6] prune_out_channels on backbone.blocks.4.0._bn0 (BatchNorm2d(455, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.4.0._expand_conv (Conv2d(80, 455, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=16
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.0._depthwise_conv
23
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True])
torch.Size([471])
torch.Size([455])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.0._expand_conv
24
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True])
torch.Size([471])
torch.Size([455])
backbone.blocks.4.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.0._project_conv (Conv2d(455, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.0._project_conv (Conv2d(455, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.0._project_conv
22
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([112])
torch.Size([112])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,318,870
Trainable params: 3,318,870
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.4.1._expand_conv
69

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.1._expand_conv (Conv2d(112, 603, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.1._expand_conv (Conv2d(112, 603, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=69
[1] prune_out_channels on backbone.blocks.4.1._expand_conv (Conv2d(112, 603, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.1._bn0 (BatchNorm2d(603, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=69
[2] prune_out_channels on backbone.blocks.4.1._bn0 (BatchNorm2d(603, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_36(HardtanhBackward0), #idxs=69
[3] prune_out_channels on _ElementWiseOp_36(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(603, 603, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=603, bias=False)), #idxs=69
[4] prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(603, 603, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=603, bias=False)) => prune_out_channels on backbone.blocks.4.1._bn1 (BatchNorm2d(603, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=69
[5] prune_out_channels on backbone.blocks.4.1._bn1 (BatchNorm2d(603, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_35(HardtanhBackward0), #idxs=69
[6] prune_out_channels on _ElementWiseOp_35(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.1._project_conv (Conv2d(603, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=69
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.1._expand_conv
21
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False, False, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True, False])
torch.Size([672])
torch.Size([603])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.1._depthwise_conv
20
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False, False, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True, False])
torch.Size([672])
torch.Size([603])
backbone.blocks.4.1._depthwise_conv
145
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(458, 458, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=458, bias=False)) => prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(458, 458, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=458, bias=False)), #idxs=145
[1] prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(458, 458, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=458, bias=False)) => prune_out_channels on _ElementWiseOp_36(HardtanhBackward0), #idxs=145
[2] prune_out_channels on backbone.blocks.4.1._depthwise_conv (Conv2d(458, 458, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=458, bias=False)) => prune_out_channels on backbone.blocks.4.1._bn1 (BatchNorm2d(458, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=145
[3] prune_out_channels on backbone.blocks.4.1._bn1 (BatchNorm2d(458, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_35(HardtanhBackward0), #idxs=145
[4] prune_out_channels on _ElementWiseOp_35(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.1._project_conv (Conv2d(458, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=145
[5] prune_out_channels on _ElementWiseOp_36(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.1._bn0 (BatchNorm2d(458, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=145
[6] prune_out_channels on backbone.blocks.4.1._bn0 (BatchNorm2d(458, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.4.1._expand_conv (Conv2d(112, 458, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=145
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.1._depthwise_conv
20
tensor([ True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True, False,  True,  True,  True,
        False,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
        False, False,  True,  True,  True,  True,  True, False, False,  True,
        False,  True, False, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True, False,  True,  True, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False, False,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True, False,
         True, False,  True,  True, False,  True, False,  True, False,  True,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True, False,
        False, False,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True, False, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
         True, False, False,  True,  True, False,  True, False,  True,  True,
         True, False, False,  True, False,  True, False, False,  True, False,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
        False,  True,  True])
torch.Size([603])
torch.Size([458])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.1._expand_conv
21
tensor([ True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True, False, False,  True, False,  True,  True,  True,
        False,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
        False, False,  True,  True,  True,  True,  True, False, False,  True,
        False,  True, False, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True, False,  True,  True, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False, False,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True, False,
         True, False,  True,  True, False,  True, False,  True, False,  True,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True, False,
        False, False,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True, False, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
         True, False, False,  True,  True, False,  True, False,  True,  True,
         True, False, False,  True, False,  True, False, False,  True, False,
         True,  True,  True,  True,  True, False,  True,  True, False,  True,
        False,  True,  True])
torch.Size([603])
torch.Size([458])
backbone.blocks.4.1._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.1._project_conv (Conv2d(458, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.1._project_conv (Conv2d(458, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.1._project_conv
19
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([112])
torch.Size([112])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 672, 10, 10]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,264,728
Trainable params: 3,264,728
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.4.2._expand_conv
109

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.2._expand_conv (Conv2d(112, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.2._expand_conv (Conv2d(112, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=109
[1] prune_out_channels on backbone.blocks.4.2._expand_conv (Conv2d(112, 563, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.2._bn0 (BatchNorm2d(563, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=109
[2] prune_out_channels on backbone.blocks.4.2._bn0 (BatchNorm2d(563, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_38(HardtanhBackward0), #idxs=109
[3] prune_out_channels on _ElementWiseOp_38(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(563, 563, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=563, bias=False)), #idxs=109
[4] prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(563, 563, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=563, bias=False)) => prune_out_channels on backbone.blocks.4.2._bn1 (BatchNorm2d(563, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=109
[5] prune_out_channels on backbone.blocks.4.2._bn1 (BatchNorm2d(563, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_37(HardtanhBackward0), #idxs=109
[6] prune_out_channels on _ElementWiseOp_37(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.2._project_conv (Conv2d(563, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=109
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.2._expand_conv
18
tensor([ True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True, False, False,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True, False,  True,  True, False,  True, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True, False,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
        False,  True, False,  True,  True,  True,  True, False, False,  True,
         True,  True, False,  True, False, False,  True, False,  True, False,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True, False])
torch.Size([672])
torch.Size([563])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.2._depthwise_conv
17
tensor([ True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True,  True, False, False,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False,  True, False,  True,  True, False,  True, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True, False,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False, False,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True,  True, False,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
        False,  True, False,  True,  True,  True,  True, False, False,  True,
         True,  True, False,  True, False, False,  True, False,  True, False,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True, False])
torch.Size([672])
torch.Size([563])
backbone.blocks.4.2._depthwise_conv
220
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(343, 343, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=343, bias=False)) => prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(343, 343, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=343, bias=False)), #idxs=220
[1] prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(343, 343, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=343, bias=False)) => prune_out_channels on _ElementWiseOp_38(HardtanhBackward0), #idxs=220
[2] prune_out_channels on backbone.blocks.4.2._depthwise_conv (Conv2d(343, 343, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=343, bias=False)) => prune_out_channels on backbone.blocks.4.2._bn1 (BatchNorm2d(343, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=220
[3] prune_out_channels on backbone.blocks.4.2._bn1 (BatchNorm2d(343, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_37(HardtanhBackward0), #idxs=220
[4] prune_out_channels on _ElementWiseOp_37(HardtanhBackward0) => prune_in_channels on backbone.blocks.4.2._project_conv (Conv2d(343, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=220
[5] prune_out_channels on _ElementWiseOp_38(HardtanhBackward0) => prune_out_channels on backbone.blocks.4.2._bn0 (BatchNorm2d(343, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=220
[6] prune_out_channels on backbone.blocks.4.2._bn0 (BatchNorm2d(343, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.4.2._expand_conv (Conv2d(112, 343, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=220
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.4.2._depthwise_conv
17
tensor([False,  True, False, False,  True, False,  True, False,  True, False,
         True,  True, False, False,  True, False, False,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False, False, False, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False, False, False, False,  True,  True,  True, False, False, False,
        False,  True, False,  True, False,  True, False, False,  True,  True,
        False, False, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True, False, False, False,  True,  True, False,
        False, False, False, False, False, False, False,  True, False,  True,
        False,  True, False, False,  True, False, False, False,  True,  True,
         True,  True,  True, False,  True, False,  True, False, False,  True,
        False,  True,  True, False, False,  True, False, False, False,  True,
         True,  True, False,  True, False,  True, False,  True, False,  True,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False, False,  True,
        False,  True, False, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True, False,  True, False, False,  True,
         True, False,  True, False, False, False,  True,  True, False,  True,
         True,  True, False, False, False,  True,  True,  True,  True, False,
        False, False,  True,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True, False,  True, False,  True,  True,  True,
         True, False,  True, False, False, False,  True, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True, False,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True, False,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True, False, False, False,
        False,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False,  True, False, False,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
        False, False,  True,  True, False, False,  True,  True, False,  True,
        False,  True,  True,  True, False,  True, False,  True, False, False,
         True, False,  True,  True, False,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
        False,  True, False, False, False,  True,  True,  True,  True, False,
        False, False,  True, False, False,  True,  True,  True, False, False,
        False, False, False,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True, False, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True, False,
         True, False,  True,  True,  True, False, False, False,  True,  True,
        False, False,  True,  True,  True, False,  True,  True,  True,  True,
         True, False, False,  True, False,  True,  True, False,  True, False,
        False,  True,  True,  True,  True, False, False,  True, False,  True,
         True, False,  True,  True, False,  True, False,  True, False, False,
        False, False,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True, False, False, False,
         True, False,  True,  True, False,  True, False,  True, False,  True,
         True,  True,  True,  True, False,  True, False,  True,  True,  True,
         True, False,  True, False,  True, False,  True, False, False, False,
         True,  True,  True])
torch.Size([563])
torch.Size([343])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.2._expand_conv
18
tensor([False,  True, False, False,  True, False,  True, False,  True, False,
         True,  True, False, False,  True, False, False,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False, False, False, False, False,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
        False, False, False, False,  True,  True,  True, False, False, False,
        False,  True, False,  True, False,  True, False, False,  True,  True,
        False, False, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True, False, False, False,  True,  True, False,
        False, False, False, False, False, False, False,  True, False,  True,
        False,  True, False, False,  True, False, False, False,  True,  True,
         True,  True,  True, False,  True, False,  True, False, False,  True,
        False,  True,  True, False, False,  True, False, False, False,  True,
         True,  True, False,  True, False,  True, False,  True, False,  True,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False, False,  True,
        False,  True, False, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True, False,  True, False, False,  True,
         True, False,  True, False, False, False,  True,  True, False,  True,
         True,  True, False, False, False,  True,  True,  True,  True, False,
        False, False,  True,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True, False,  True, False,  True,  True,  True,
         True, False,  True, False, False, False,  True, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True, False,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True, False,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True, False, False, False,
        False,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False,  True, False, False,  True,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
        False, False,  True,  True, False, False,  True,  True, False,  True,
        False,  True,  True,  True, False,  True, False,  True, False, False,
         True, False,  True,  True, False,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True, False,  True,  True,  True,
        False,  True, False, False, False,  True,  True,  True,  True, False,
        False, False,  True, False, False,  True,  True,  True, False, False,
        False, False, False,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False, False,  True, False, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True, False,
         True, False,  True,  True,  True, False, False, False,  True,  True,
        False, False,  True,  True,  True, False,  True,  True,  True,  True,
         True, False, False,  True, False,  True,  True, False,  True, False,
        False,  True,  True,  True,  True, False, False,  True, False,  True,
         True, False,  True,  True, False,  True, False,  True, False, False,
        False, False,  True,  True, False,  True,  True,  True,  True, False,
         True,  True,  True, False,  True,  True,  True, False, False, False,
         True, False,  True,  True, False,  True, False,  True, False,  True,
         True,  True,  True,  True, False,  True, False,  True,  True,  True,
         True, False,  True, False,  True, False,  True, False, False, False,
         True,  True,  True])
torch.Size([563])
torch.Size([343])
backbone.blocks.4.2._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.4.2._project_conv (Conv2d(343, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.4.2._project_conv (Conv2d(343, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.4.2._project_conv
16
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True])
torch.Size([112])
torch.Size([112])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 672, 10, 10]          75,264          75,264
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 672, 10, 10]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 672, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 672, 5, 5]          16,800          16,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 672, 5, 5]           1,344           1,344
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]         129,024         129,024
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,181,491
Trainable params: 3,181,491
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.5.0._expand_conv
236

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.0._expand_conv (Conv2d(112, 436, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.0._expand_conv (Conv2d(112, 436, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=236
[1] prune_out_channels on backbone.blocks.5.0._expand_conv (Conv2d(112, 436, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.0._bn0 (BatchNorm2d(436, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=236
[2] prune_out_channels on backbone.blocks.5.0._bn0 (BatchNorm2d(436, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_10(HardtanhBackward0), #idxs=236
[3] prune_out_channels on _ElementWiseOp_10(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(436, 436, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=436, bias=False)), #idxs=236
[4] prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(436, 436, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=436, bias=False)) => prune_out_channels on backbone.blocks.5.0._bn1 (BatchNorm2d(436, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=236
[5] prune_out_channels on backbone.blocks.5.0._bn1 (BatchNorm2d(436, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_9(HardtanhBackward0), #idxs=236
[6] prune_out_channels on _ElementWiseOp_9(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.0._project_conv (Conv2d(436, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=236
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.0._expand_conv
15
tensor([False,  True,  True,  True, False,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True, False,  True, False, False,  True,
         True,  True, False, False, False, False,  True,  True,  True,  True,
         True,  True, False, False, False, False,  True,  True, False, False,
         True,  True,  True,  True,  True, False,  True,  True, False, False,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False,  True,  True, False, False,  True,  True,  True,
         True,  True,  True, False,  True, False,  True,  True, False, False,
         True,  True, False,  True, False,  True, False,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True, False, False,  True, False,  True,  True,
         True,  True,  True,  True, False,  True, False,  True, False,  True,
         True, False,  True,  True,  True, False, False,  True, False,  True,
         True,  True, False,  True, False,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True, False, False, False,  True,
        False, False,  True,  True,  True,  True, False,  True, False, False,
         True, False, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True, False, False,  True,  True, False,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True, False, False, False, False, False, False, False,
         True, False, False, False,  True,  True, False,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True,  True, False,
         True, False, False, False,  True,  True, False,  True, False,  True,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True, False,  True, False, False,  True,
         True, False,  True, False, False,  True, False,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True, False, False,
        False,  True, False,  True, False,  True,  True,  True, False,  True,
         True,  True, False, False, False,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True,  True, False, False, False, False, False,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True, False,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True,  True, False,  True, False,  True, False,
         True,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
         True, False, False,  True, False, False,  True,  True, False, False,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
        False,  True,  True, False, False, False, False,  True, False, False,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
        False, False, False, False, False,  True,  True, False, False,  True,
         True, False,  True,  True, False,  True, False,  True, False, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True, False, False, False,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False, False,  True,  True,  True,  True, False, False,
         True,  True,  True,  True, False,  True, False, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True,  True, False,  True,  True, False,
         True,  True])
torch.Size([672])
torch.Size([436])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.0._depthwise_conv
14
tensor([False,  True,  True,  True, False,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True,  True, False,  True, False,  True, False, False,  True,
         True,  True, False, False, False, False,  True,  True,  True,  True,
         True,  True, False, False, False, False,  True,  True, False, False,
         True,  True,  True,  True,  True, False,  True,  True, False, False,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False,  True,  True, False, False,  True,  True,  True,
         True,  True,  True, False,  True, False,  True,  True, False, False,
         True,  True, False,  True, False,  True, False,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
        False,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True, False, False,  True, False,  True,  True,
         True,  True,  True,  True, False,  True, False,  True, False,  True,
         True, False,  True,  True,  True, False, False,  True, False,  True,
         True,  True, False,  True, False,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True, False, False, False,  True,
        False, False,  True,  True,  True,  True, False,  True, False, False,
         True, False, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True, False, False,  True,  True, False,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True, False, False, False, False, False, False, False,
         True, False, False, False,  True,  True, False,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True,  True, False,
         True, False, False, False,  True,  True, False,  True, False,  True,
        False,  True, False,  True, False, False,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True, False,  True, False, False,  True,
         True, False,  True, False, False,  True, False,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True, False, False,
        False,  True, False,  True, False,  True,  True,  True, False,  True,
         True,  True, False, False, False,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True,  True, False,
         True,  True, False,  True,  True, False, False, False, False, False,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True, False,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True,  True, False,  True, False,  True, False,
         True,  True, False, False, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
         True, False, False,  True, False, False,  True,  True, False, False,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
        False,  True,  True, False, False, False, False,  True, False, False,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
        False, False, False, False, False,  True,  True, False, False,  True,
         True, False,  True,  True, False,  True, False,  True, False, False,
         True,  True,  True,  True, False,  True,  True,  True, False,  True,
         True,  True, False, False, False,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True, False,
         True,  True, False, False,  True,  True,  True,  True, False, False,
         True,  True,  True,  True, False,  True, False, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True,  True, False,  True,  True, False,
         True,  True])
torch.Size([672])
torch.Size([436])
backbone.blocks.5.0._depthwise_conv
9
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(427, 427, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=427, bias=False)) => prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(427, 427, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=427, bias=False)), #idxs=9
[1] prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(427, 427, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=427, bias=False)) => prune_out_channels on _ElementWiseOp_10(HardtanhBackward0), #idxs=9
[2] prune_out_channels on backbone.blocks.5.0._depthwise_conv (Conv2d(427, 427, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=427, bias=False)) => prune_out_channels on backbone.blocks.5.0._bn1 (BatchNorm2d(427, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[3] prune_out_channels on backbone.blocks.5.0._bn1 (BatchNorm2d(427, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_9(HardtanhBackward0), #idxs=9
[4] prune_out_channels on _ElementWiseOp_9(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.0._project_conv (Conv2d(427, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
[5] prune_out_channels on _ElementWiseOp_10(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.0._bn0 (BatchNorm2d(427, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=9
[6] prune_out_channels on backbone.blocks.5.0._bn0 (BatchNorm2d(427, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.5.0._expand_conv (Conv2d(112, 427, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=9
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.0._depthwise_conv
14
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True])
torch.Size([436])
torch.Size([427])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.0._expand_conv
15
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True])
torch.Size([436])
torch.Size([427])
backbone.blocks.5.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.0._project_conv (Conv2d(427, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.0._project_conv (Conv2d(427, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.0._project_conv
13
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([192])
torch.Size([192])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 3,099,906
Trainable params: 3,099,906
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.5.1._expand_conv
178

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.1._expand_conv (Conv2d(192, 974, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.1._expand_conv (Conv2d(192, 974, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=178
[1] prune_out_channels on backbone.blocks.5.1._expand_conv (Conv2d(192, 974, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.1._bn0 (BatchNorm2d(974, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=178
[2] prune_out_channels on backbone.blocks.5.1._bn0 (BatchNorm2d(974, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_40(HardtanhBackward0), #idxs=178
[3] prune_out_channels on _ElementWiseOp_40(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(974, 974, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=974, bias=False)), #idxs=178
[4] prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(974, 974, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=974, bias=False)) => prune_out_channels on backbone.blocks.5.1._bn1 (BatchNorm2d(974, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=178
[5] prune_out_channels on backbone.blocks.5.1._bn1 (BatchNorm2d(974, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_39(HardtanhBackward0), #idxs=178
[6] prune_out_channels on _ElementWiseOp_39(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.1._project_conv (Conv2d(974, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=178
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.1._expand_conv
12
tensor([False,  True, False,  ...,  True,  True,  True])
torch.Size([1152])
torch.Size([974])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.1._depthwise_conv
11
tensor([False,  True, False,  ...,  True,  True,  True])
torch.Size([1152])
torch.Size([974])
backbone.blocks.5.1._depthwise_conv
301
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(673, 673, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=673, bias=False)) => prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(673, 673, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=673, bias=False)), #idxs=301
[1] prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(673, 673, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=673, bias=False)) => prune_out_channels on _ElementWiseOp_40(HardtanhBackward0), #idxs=301
[2] prune_out_channels on backbone.blocks.5.1._depthwise_conv (Conv2d(673, 673, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=673, bias=False)) => prune_out_channels on backbone.blocks.5.1._bn1 (BatchNorm2d(673, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=301
[3] prune_out_channels on backbone.blocks.5.1._bn1 (BatchNorm2d(673, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_39(HardtanhBackward0), #idxs=301
[4] prune_out_channels on _ElementWiseOp_39(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.1._project_conv (Conv2d(673, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=301
[5] prune_out_channels on _ElementWiseOp_40(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.1._bn0 (BatchNorm2d(673, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=301
[6] prune_out_channels on backbone.blocks.5.1._bn0 (BatchNorm2d(673, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.5.1._expand_conv (Conv2d(192, 673, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=301
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.1._depthwise_conv
11
tensor([False,  True,  True,  True,  True,  True, False, False,  True,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False,  True,  True, False, False, False, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True, False,  True,  True, False, False,  True, False,  True,  True,
         True, False,  True, False,  True,  True,  True,  True, False,  True,
         True, False, False, False,  True,  True,  True,  True, False, False,
         True,  True, False,  True,  True, False, False,  True, False, False,
        False, False,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False, False,  True, False,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True, False,  True,  True, False, False,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True, False, False,  True, False,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
        False, False,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True, False, False,  True, False,  True,
         True, False,  True, False,  True, False, False, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
        False,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False, False,  True, False,
        False,  True,  True,  True, False,  True,  True, False, False,  True,
         True,  True,  True, False, False,  True, False,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False, False, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True, False, False, False, False,  True, False,
        False, False, False, False, False, False,  True, False,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False,  True, False,  True,  True, False, False, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True, False, False,  True,  True,  True,  True,  True, False, False,
        False, False,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False, False,
        False,  True,  True, False,  True, False,  True, False, False,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
         True,  True,  True,  True, False, False,  True, False, False,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
        False,  True,  True, False, False, False,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True, False,  True,  True,  True, False,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True, False, False, False,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False, False, False,
         True, False, False,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False, False,
         True, False,  True,  True, False, False, False,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True, False,  True, False,  True, False, False,  True,
        False,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True, False, False,
         True, False, False, False, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True, False,  True,
         True, False, False,  True,  True, False, False,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True, False, False,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True, False, False, False,  True, False,
        False,  True,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False])
torch.Size([974])
torch.Size([673])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.1._expand_conv
12
tensor([False,  True,  True,  True,  True,  True, False, False,  True,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False,  True,  True, False, False, False, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True, False,  True,  True, False, False,  True, False,  True,  True,
         True, False,  True, False,  True,  True,  True,  True, False,  True,
         True, False, False, False,  True,  True,  True,  True, False, False,
         True,  True, False,  True,  True, False, False,  True, False, False,
        False, False,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False, False,  True, False,
         True, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True, False,  True,  True, False, False,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True, False,  True, False, False,  True, False,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
        False,  True, False,  True, False,  True,  True,  True,  True,  True,
        False, False,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True, False, False,  True, False,  True,
         True, False,  True, False,  True, False, False, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
        False,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False, False,  True, False,
        False,  True,  True,  True, False,  True,  True, False, False,  True,
         True,  True,  True, False, False,  True, False,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False, False, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True, False, False, False, False,  True, False,
        False, False, False, False, False, False,  True, False,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True,  True, False,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False,  True, False,  True,  True, False, False, False,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True, False,
         True, False, False,  True,  True,  True,  True,  True, False, False,
        False, False,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False, False,
        False,  True,  True, False,  True, False,  True, False, False,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
         True,  True,  True,  True, False, False,  True, False, False,  True,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True, False,  True,  True, False,  True,  True,
        False,  True,  True, False, False, False,  True,  True, False,  True,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
        False,  True,  True, False,  True,  True,  True, False,  True,  True,
         True, False,  True,  True, False,  True,  True,  True,  True, False,
        False, False,  True,  True,  True,  True,  True, False,  True,  True,
         True, False, False, False,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True, False,  True, False, False,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True, False, False, False, False,
         True, False, False,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True, False, False,
         True, False,  True,  True, False, False, False,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True, False, False,  True,  True,
        False,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
         True, False,  True, False,  True, False,  True, False, False,  True,
        False,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True, False,  True,  True,  True, False, False,
         True, False, False, False, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True,  True, False, False,  True,  True,
         True,  True,  True,  True,  True, False, False,  True, False,  True,
         True, False, False,  True,  True, False, False,  True,  True,  True,
         True, False,  True,  True, False,  True,  True,  True, False, False,
         True,  True,  True,  True,  True, False, False,  True,  True, False,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True, False,
         True,  True,  True,  True,  True, False, False, False,  True, False,
        False,  True,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False])
torch.Size([974])
torch.Size([673])
backbone.blocks.5.1._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.1._project_conv (Conv2d(673, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.1._project_conv (Conv2d(673, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.1._project_conv
10
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([192])
torch.Size([192])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86       [1, 673, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88       [1, 673, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89       [1, 673, 5, 5]          16,825          16,825
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 2,902,079
Trainable params: 2,902,079
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.5.2._expand_conv
368

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.2._expand_conv (Conv2d(192, 784, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.2._expand_conv (Conv2d(192, 784, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=368
[1] prune_out_channels on backbone.blocks.5.2._expand_conv (Conv2d(192, 784, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.2._bn0 (BatchNorm2d(784, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=368
[2] prune_out_channels on backbone.blocks.5.2._bn0 (BatchNorm2d(784, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_42(HardtanhBackward0), #idxs=368
[3] prune_out_channels on _ElementWiseOp_42(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(784, 784, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=784, bias=False)), #idxs=368
[4] prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(784, 784, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=784, bias=False)) => prune_out_channels on backbone.blocks.5.2._bn1 (BatchNorm2d(784, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=368
[5] prune_out_channels on backbone.blocks.5.2._bn1 (BatchNorm2d(784, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_41(HardtanhBackward0), #idxs=368
[6] prune_out_channels on _ElementWiseOp_41(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.2._project_conv (Conv2d(784, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=368
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.2._expand_conv
9
tensor([ True,  True, False,  ..., False, False,  True])
torch.Size([1152])
torch.Size([784])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.2._depthwise_conv
8
tensor([ True,  True, False,  ..., False, False,  True])
torch.Size([1152])
torch.Size([784])
backbone.blocks.5.2._depthwise_conv
372
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(412, 412, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=412, bias=False)) => prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(412, 412, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=412, bias=False)), #idxs=372
[1] prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(412, 412, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=412, bias=False)) => prune_out_channels on _ElementWiseOp_42(HardtanhBackward0), #idxs=372
[2] prune_out_channels on backbone.blocks.5.2._depthwise_conv (Conv2d(412, 412, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=412, bias=False)) => prune_out_channels on backbone.blocks.5.2._bn1 (BatchNorm2d(412, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=372
[3] prune_out_channels on backbone.blocks.5.2._bn1 (BatchNorm2d(412, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_41(HardtanhBackward0), #idxs=372
[4] prune_out_channels on _ElementWiseOp_41(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.2._project_conv (Conv2d(412, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=372
[5] prune_out_channels on _ElementWiseOp_42(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.2._bn0 (BatchNorm2d(412, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=372
[6] prune_out_channels on backbone.blocks.5.2._bn0 (BatchNorm2d(412, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.5.2._expand_conv (Conv2d(192, 412, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=372
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.2._depthwise_conv
8
tensor([False,  True,  True, False,  True,  True,  True,  True, False,  True,
         True, False,  True,  True, False,  True, False, False, False, False,
         True, False,  True,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True, False,  True, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False, False,  True, False,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True, False, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True, False, False, False, False, False, False, False,  True,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False, False,  True, False,  True, False,  True,  True, False,
        False, False, False, False, False,  True, False,  True, False,  True,
        False,  True,  True, False,  True, False, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True, False, False,  True,  True, False, False, False, False,
        False,  True, False, False,  True,  True, False,  True,  True, False,
         True, False,  True,  True,  True, False, False, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True, False,
         True,  True, False, False, False,  True,  True, False, False, False,
        False, False, False, False,  True,  True, False,  True, False, False,
         True, False, False, False, False,  True,  True,  True, False, False,
         True, False,  True, False,  True,  True,  True,  True, False, False,
        False, False,  True, False,  True,  True, False,  True, False, False,
         True, False, False, False, False, False,  True,  True,  True, False,
         True, False, False, False, False,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False, False,  True,  True, False, False,  True, False,
        False, False, False,  True, False, False, False, False, False,  True,
         True, False,  True,  True, False,  True,  True, False, False,  True,
        False,  True, False,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
        False,  True,  True, False, False, False,  True, False,  True,  True,
         True, False,  True,  True,  True, False,  True, False,  True, False,
         True,  True, False, False,  True, False, False,  True,  True, False,
         True, False,  True, False, False, False,  True,  True,  True, False,
         True,  True, False, False,  True, False,  True,  True, False,  True,
        False, False, False, False, False,  True,  True,  True,  True,  True,
        False,  True, False, False, False, False,  True, False, False, False,
        False, False, False,  True,  True, False,  True,  True, False, False,
        False,  True,  True, False,  True,  True,  True, False, False,  True,
        False,  True,  True, False,  True,  True, False,  True, False, False,
        False,  True, False,  True, False, False,  True,  True, False, False,
         True, False,  True,  True, False,  True,  True, False, False, False,
         True, False,  True,  True,  True,  True,  True, False, False, False,
        False, False,  True,  True,  True, False, False, False,  True, False,
         True,  True, False, False, False,  True, False, False,  True,  True,
         True,  True, False, False, False, False, False,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False, False,  True,
        False, False, False, False,  True, False, False, False, False, False,
         True, False, False,  True,  True,  True, False,  True, False,  True,
        False, False, False,  True, False,  True, False, False,  True, False,
        False, False,  True,  True, False,  True, False, False, False, False,
         True,  True, False,  True,  True, False,  True,  True, False,  True,
         True,  True,  True, False, False,  True,  True, False,  True,  True,
        False, False,  True,  True, False,  True, False,  True,  True, False,
        False,  True,  True, False, False, False,  True,  True, False,  True,
         True,  True, False,  True, False, False, False,  True, False,  True,
        False, False, False, False,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False,  True, False, False, False,  True, False,
        False,  True,  True, False, False, False,  True,  True, False, False,
         True,  True,  True,  True, False,  True,  True, False, False,  True,
         True, False,  True,  True, False, False,  True,  True, False, False,
        False,  True, False, False,  True, False,  True, False, False, False,
         True,  True,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True,  True, False, False,  True,  True,
        False, False, False,  True, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True, False,  True, False,  True,  True,
        False,  True, False, False,  True,  True, False, False, False,  True,
        False, False, False, False,  True,  True,  True, False,  True, False,
         True, False, False,  True, False,  True, False, False,  True, False,
        False,  True, False, False, False,  True,  True, False,  True,  True,
         True,  True, False,  True, False, False,  True,  True,  True, False,
         True,  True, False,  True,  True, False, False,  True, False,  True,
        False,  True, False,  True, False, False,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([784])
torch.Size([412])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.2._expand_conv
9
tensor([False,  True,  True, False,  True,  True,  True,  True, False,  True,
         True, False,  True,  True, False,  True, False, False, False, False,
         True, False,  True,  True, False,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
        False,  True, False,  True,  True, False,  True, False,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False, False,  True, False,  True, False,  True,  True,  True, False,
         True,  True, False,  True,  True, False, False,  True,  True,  True,
        False,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True, False, False, False, False, False, False, False,  True,
        False,  True, False,  True,  True, False,  True,  True,  True,  True,
         True, False, False,  True, False,  True, False,  True,  True, False,
        False, False, False, False, False,  True, False,  True, False,  True,
        False,  True,  True, False,  True, False, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
         True,  True, False, False,  True,  True, False, False, False, False,
        False,  True, False, False,  True,  True, False,  True,  True, False,
         True, False,  True,  True,  True, False, False, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True, False,
         True,  True, False, False, False,  True,  True, False, False, False,
        False, False, False, False,  True,  True, False,  True, False, False,
         True, False, False, False, False,  True,  True,  True, False, False,
         True, False,  True, False,  True,  True,  True,  True, False, False,
        False, False,  True, False,  True,  True, False,  True, False, False,
         True, False, False, False, False, False,  True,  True,  True, False,
         True, False, False, False, False,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True, False,  True,  True,  True,  True,
        False,  True, False, False,  True,  True, False, False,  True, False,
        False, False, False,  True, False, False, False, False, False,  True,
         True, False,  True,  True, False,  True,  True, False, False,  True,
        False,  True, False,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False,  True, False,  True,  True,  True, False,
        False,  True,  True, False, False, False,  True, False,  True,  True,
         True, False,  True,  True,  True, False,  True, False,  True, False,
         True,  True, False, False,  True, False, False,  True,  True, False,
         True, False,  True, False, False, False,  True,  True,  True, False,
         True,  True, False, False,  True, False,  True,  True, False,  True,
        False, False, False, False, False,  True,  True,  True,  True,  True,
        False,  True, False, False, False, False,  True, False, False, False,
        False, False, False,  True,  True, False,  True,  True, False, False,
        False,  True,  True, False,  True,  True,  True, False, False,  True,
        False,  True,  True, False,  True,  True, False,  True, False, False,
        False,  True, False,  True, False, False,  True,  True, False, False,
         True, False,  True,  True, False,  True,  True, False, False, False,
         True, False,  True,  True,  True,  True,  True, False, False, False,
        False, False,  True,  True,  True, False, False, False,  True, False,
         True,  True, False, False, False,  True, False, False,  True,  True,
         True,  True, False, False, False, False, False,  True,  True,  True,
         True,  True,  True, False, False,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False, False,  True,
        False, False, False, False,  True, False, False, False, False, False,
         True, False, False,  True,  True,  True, False,  True, False,  True,
        False, False, False,  True, False,  True, False, False,  True, False,
        False, False,  True,  True, False,  True, False, False, False, False,
         True,  True, False,  True,  True, False,  True,  True, False,  True,
         True,  True,  True, False, False,  True,  True, False,  True,  True,
        False, False,  True,  True, False,  True, False,  True,  True, False,
        False,  True,  True, False, False, False,  True,  True, False,  True,
         True,  True, False,  True, False, False, False,  True, False,  True,
        False, False, False, False,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True,  True, False,  True,
         True,  True, False, False,  True, False, False, False,  True, False,
        False,  True,  True, False, False, False,  True,  True, False, False,
         True,  True,  True,  True, False,  True,  True, False, False,  True,
         True, False,  True,  True, False, False,  True,  True, False, False,
        False,  True, False, False,  True, False,  True, False, False, False,
         True,  True,  True, False,  True,  True,  True, False,  True,  True,
        False,  True,  True, False,  True,  True, False, False,  True,  True,
        False, False, False,  True, False,  True,  True,  True,  True, False,
        False,  True,  True, False,  True, False,  True, False,  True,  True,
        False,  True, False, False,  True,  True, False, False, False,  True,
        False, False, False, False,  True,  True,  True, False,  True, False,
         True, False, False,  True, False,  True, False, False,  True, False,
        False,  True, False, False, False,  True,  True, False,  True,  True,
         True,  True, False,  True, False, False,  True,  True,  True, False,
         True,  True, False,  True,  True, False, False,  True, False,  True,
        False,  True, False,  True, False, False,  True, False,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True])
torch.Size([784])
torch.Size([412])
backbone.blocks.5.2._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.2._project_conv (Conv2d(412, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.2._project_conv (Conv2d(412, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.2._project_conv
7
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([192])
torch.Size([192])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86       [1, 673, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88       [1, 673, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89       [1, 673, 5, 5]          16,825          16,825
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93       [1, 412, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95       [1, 412, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96       [1, 412, 5, 5]          10,300          10,300
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103      [1, 1152, 5, 5]          28,800          28,800
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 2,596,459
Trainable params: 2,596,459
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.5.3._expand_conv
513

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.3._expand_conv (Conv2d(192, 639, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.3._expand_conv (Conv2d(192, 639, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=513
[1] prune_out_channels on backbone.blocks.5.3._expand_conv (Conv2d(192, 639, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.3._bn0 (BatchNorm2d(639, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=513
[2] prune_out_channels on backbone.blocks.5.3._bn0 (BatchNorm2d(639, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_44(HardtanhBackward0), #idxs=513
[3] prune_out_channels on _ElementWiseOp_44(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(639, 639, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=639, bias=False)), #idxs=513
[4] prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(639, 639, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=639, bias=False)) => prune_out_channels on backbone.blocks.5.3._bn1 (BatchNorm2d(639, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=513
[5] prune_out_channels on backbone.blocks.5.3._bn1 (BatchNorm2d(639, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_43(HardtanhBackward0), #idxs=513
[6] prune_out_channels on _ElementWiseOp_43(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.3._project_conv (Conv2d(639, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=513
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.3._expand_conv
6
tensor([ True, False, False,  ...,  True, False, False])
torch.Size([1152])
torch.Size([639])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.3._depthwise_conv
5
tensor([ True, False, False,  ...,  True, False, False])
torch.Size([1152])
torch.Size([639])
backbone.blocks.5.3._depthwise_conv
321
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(318, 318, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=318, bias=False)) => prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(318, 318, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=318, bias=False)), #idxs=321
[1] prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(318, 318, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=318, bias=False)) => prune_out_channels on _ElementWiseOp_44(HardtanhBackward0), #idxs=321
[2] prune_out_channels on backbone.blocks.5.3._depthwise_conv (Conv2d(318, 318, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=318, bias=False)) => prune_out_channels on backbone.blocks.5.3._bn1 (BatchNorm2d(318, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=321
[3] prune_out_channels on backbone.blocks.5.3._bn1 (BatchNorm2d(318, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_43(HardtanhBackward0), #idxs=321
[4] prune_out_channels on _ElementWiseOp_43(HardtanhBackward0) => prune_in_channels on backbone.blocks.5.3._project_conv (Conv2d(318, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=321
[5] prune_out_channels on _ElementWiseOp_44(HardtanhBackward0) => prune_out_channels on backbone.blocks.5.3._bn0 (BatchNorm2d(318, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=321
[6] prune_out_channels on backbone.blocks.5.3._bn0 (BatchNorm2d(318, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.5.3._expand_conv (Conv2d(192, 318, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=321
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.5.3._depthwise_conv
5
tensor([False, False, False,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False, False, False,  True,  True, False, False,  True,
        False, False,  True, False, False,  True,  True,  True, False,  True,
        False, False,  True,  True,  True, False,  True, False, False, False,
        False,  True,  True, False, False, False,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True, False, False,
        False,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True, False, False,  True,  True,
        False, False,  True,  True, False,  True, False, False,  True, False,
         True, False,  True,  True,  True,  True, False, False, False,  True,
        False,  True, False, False,  True, False,  True,  True, False,  True,
        False, False,  True, False, False, False, False,  True,  True, False,
        False,  True,  True, False, False,  True, False, False, False,  True,
         True,  True,  True, False, False,  True,  True, False, False,  True,
        False, False,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False, False, False, False, False,  True, False,  True,
        False,  True,  True,  True,  True, False, False,  True,  True,  True,
        False, False, False,  True, False,  True,  True, False,  True, False,
         True, False,  True, False, False, False,  True, False, False, False,
         True,  True, False, False, False,  True,  True,  True,  True, False,
        False,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True, False,  True,
         True, False,  True, False, False, False, False, False, False, False,
        False,  True,  True, False,  True,  True, False,  True,  True, False,
        False, False,  True,  True,  True, False,  True, False, False, False,
        False, False, False, False, False,  True, False, False, False, False,
        False, False, False, False,  True, False, False,  True, False, False,
         True,  True, False, False, False, False, False,  True, False, False,
         True,  True, False, False,  True,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False, False,
        False, False, False,  True, False,  True,  True,  True, False, False,
        False,  True,  True, False, False,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
        False, False,  True, False, False,  True,  True,  True,  True,  True,
         True, False, False,  True, False,  True, False, False,  True, False,
         True,  True, False, False,  True,  True, False,  True, False, False,
         True, False, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True, False, False,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True, False, False, False,  True,  True, False, False,  True, False,
        False,  True,  True, False,  True, False, False, False, False,  True,
        False, False, False,  True, False, False,  True,  True,  True,  True,
        False, False,  True, False,  True,  True, False,  True, False,  True,
         True,  True, False, False, False, False, False, False,  True, False,
         True,  True,  True, False, False, False, False, False, False, False,
        False, False,  True, False,  True,  True, False, False,  True,  True,
         True, False, False, False, False,  True,  True, False,  True,  True,
         True, False, False, False,  True, False, False, False, False, False,
        False, False,  True,  True, False, False, False,  True, False,  True,
        False, False,  True, False,  True,  True, False,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True, False, False,  True, False, False,  True, False,  True, False,
         True,  True, False, False, False,  True,  True,  True, False,  True,
        False, False, False,  True,  True,  True, False,  True, False,  True,
         True,  True,  True, False, False,  True,  True,  True, False, False,
        False,  True,  True, False, False,  True,  True,  True,  True, False,
        False, False,  True, False,  True, False,  True,  True, False, False,
         True, False, False,  True, False, False,  True, False,  True, False,
        False, False, False, False, False,  True,  True, False, False, False,
         True,  True, False,  True, False,  True, False,  True,  True, False,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
         True,  True, False, False, False, False, False, False,  True])
torch.Size([639])
torch.Size([318])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.3._expand_conv
6
tensor([False, False, False,  True,  True,  True,  True,  True,  True, False,
         True, False,  True,  True,  True,  True,  True, False, False,  True,
         True, False,  True, False,  True,  True,  True,  True,  True,  True,
         True,  True, False, False, False,  True,  True, False, False,  True,
        False, False,  True, False, False,  True,  True,  True, False,  True,
        False, False,  True,  True,  True, False,  True, False, False, False,
        False,  True,  True, False, False, False,  True,  True,  True,  True,
         True, False, False, False, False,  True, False,  True, False, False,
        False,  True, False,  True,  True,  True,  True,  True,  True, False,
         True,  True,  True,  True, False,  True, False, False,  True,  True,
        False, False,  True,  True, False,  True, False, False,  True, False,
         True, False,  True,  True,  True,  True, False, False, False,  True,
        False,  True, False, False,  True, False,  True,  True, False,  True,
        False, False,  True, False, False, False, False,  True,  True, False,
        False,  True,  True, False, False,  True, False, False, False,  True,
         True,  True,  True, False, False,  True,  True, False, False,  True,
        False, False,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False, False, False, False, False,  True, False,  True,
        False,  True,  True,  True,  True, False, False,  True,  True,  True,
        False, False, False,  True, False,  True,  True, False,  True, False,
         True, False,  True, False, False, False,  True, False, False, False,
         True,  True, False, False, False,  True,  True,  True,  True, False,
        False,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True, False,  True,  True,  True, False,  True, False,  True,
         True, False,  True, False, False, False, False, False, False, False,
        False,  True,  True, False,  True,  True, False,  True,  True, False,
        False, False,  True,  True,  True, False,  True, False, False, False,
        False, False, False, False, False,  True, False, False, False, False,
        False, False, False, False,  True, False, False,  True, False, False,
         True,  True, False, False, False, False, False,  True, False, False,
         True,  True, False, False,  True,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True,  True,  True, False, False,
        False, False, False,  True, False,  True,  True,  True, False, False,
        False,  True,  True, False, False,  True, False,  True, False,  True,
        False,  True,  True,  True, False,  True,  True, False,  True,  True,
        False, False,  True, False, False,  True,  True,  True,  True,  True,
         True, False, False,  True, False,  True, False, False,  True, False,
         True,  True, False, False,  True,  True, False,  True, False, False,
         True, False, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True, False, False,
         True,  True, False,  True, False,  True,  True,  True,  True,  True,
         True, False, False, False,  True,  True, False, False,  True, False,
        False,  True,  True, False,  True, False, False, False, False,  True,
        False, False, False,  True, False, False,  True,  True,  True,  True,
        False, False,  True, False,  True,  True, False,  True, False,  True,
         True,  True, False, False, False, False, False, False,  True, False,
         True,  True,  True, False, False, False, False, False, False, False,
        False, False,  True, False,  True,  True, False, False,  True,  True,
         True, False, False, False, False,  True,  True, False,  True,  True,
         True, False, False, False,  True, False, False, False, False, False,
        False, False,  True,  True, False, False, False,  True, False,  True,
        False, False,  True, False,  True,  True, False,  True,  True, False,
        False,  True,  True, False,  True,  True,  True,  True,  True, False,
         True, False, False,  True, False, False,  True, False,  True, False,
         True,  True, False, False, False,  True,  True,  True, False,  True,
        False, False, False,  True,  True,  True, False,  True, False,  True,
         True,  True,  True, False, False,  True,  True,  True, False, False,
        False,  True,  True, False, False,  True,  True,  True,  True, False,
        False, False,  True, False,  True, False,  True,  True, False, False,
         True, False, False,  True, False, False,  True, False,  True, False,
        False, False, False, False, False,  True,  True, False, False, False,
         True,  True, False,  True, False,  True, False,  True,  True, False,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
         True,  True, False, False, False, False, False, False,  True])
torch.Size([639])
torch.Size([318])
backbone.blocks.5.3._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.5.3._project_conv (Conv2d(318, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.5.3._project_conv (Conv2d(318, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.5.3._project_conv
4
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True])
torch.Size([192])
torch.Size([192])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86       [1, 673, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88       [1, 673, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89       [1, 673, 5, 5]          16,825          16,825
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93       [1, 412, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95       [1, 412, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96       [1, 412, 5, 5]          10,300          10,300
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100       [1, 318, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102       [1, 318, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103       [1, 318, 5, 5]           7,950           7,950
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107      [1, 1152, 5, 5]         221,184         221,184
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109      [1, 1152, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110      [1, 1152, 5, 5]          10,368          10,368
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111      [1, 1152, 5, 5]           2,304           2,304
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         368,640         368,640
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 2,252,017
Trainable params: 2,252,017
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.blocks.6.0._expand_conv
567

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.6.0._expand_conv (Conv2d(192, 585, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.6.0._expand_conv (Conv2d(192, 585, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=567
[1] prune_out_channels on backbone.blocks.6.0._expand_conv (Conv2d(192, 585, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.6.0._bn0 (BatchNorm2d(585, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=567
[2] prune_out_channels on backbone.blocks.6.0._bn0 (BatchNorm2d(585, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_5(HardtanhBackward0), #idxs=567
[3] prune_out_channels on _ElementWiseOp_5(HardtanhBackward0) => prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(585, 585, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=585, bias=False)), #idxs=567
[4] prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(585, 585, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=585, bias=False)) => prune_out_channels on backbone.blocks.6.0._bn1 (BatchNorm2d(585, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=567
[5] prune_out_channels on backbone.blocks.6.0._bn1 (BatchNorm2d(585, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_4(HardtanhBackward0), #idxs=567
[6] prune_out_channels on _ElementWiseOp_4(HardtanhBackward0) => prune_in_channels on backbone.blocks.6.0._project_conv (Conv2d(585, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=567
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.6.0._expand_conv
3
tensor([ True, False,  True,  ..., False,  True, False])
torch.Size([1152])
torch.Size([585])
<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.6.0._depthwise_conv
2
tensor([ True, False,  True,  ..., False,  True, False])
torch.Size([1152])
torch.Size([585])
backbone.blocks.6.0._depthwise_conv
109
Depthwise Detected

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(476, 476, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=476, bias=False)) => prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(476, 476, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=476, bias=False)), #idxs=109
[1] prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(476, 476, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=476, bias=False)) => prune_out_channels on _ElementWiseOp_5(HardtanhBackward0), #idxs=109
[2] prune_out_channels on backbone.blocks.6.0._depthwise_conv (Conv2d(476, 476, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=476, bias=False)) => prune_out_channels on backbone.blocks.6.0._bn1 (BatchNorm2d(476, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=109
[3] prune_out_channels on backbone.blocks.6.0._bn1 (BatchNorm2d(476, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_4(HardtanhBackward0), #idxs=109
[4] prune_out_channels on _ElementWiseOp_4(HardtanhBackward0) => prune_in_channels on backbone.blocks.6.0._project_conv (Conv2d(476, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=109
[5] prune_out_channels on _ElementWiseOp_5(HardtanhBackward0) => prune_out_channels on backbone.blocks.6.0._bn0 (BatchNorm2d(476, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=109
[6] prune_out_channels on backbone.blocks.6.0._bn0 (BatchNorm2d(476, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on backbone.blocks.6.0._expand_conv (Conv2d(192, 476, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=109
--------------------------------

<bound method DepthwiseConvPruner.prune_out_channels of <torch_pruning.pruner.function.DepthwiseConvPruner object at 0x7fcee44d14e0>>
backbone.blocks.6.0._depthwise_conv
2
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True, False,
         True,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True, False,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True, False,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False, False, False,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False, False,  True,
        False,  True,  True,  True, False, False, False,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True, False, False,  True,  True,  True,
         True, False, False,  True,  True,  True,  True, False,  True,  True,
        False,  True,  True,  True,  True])
torch.Size([585])
torch.Size([476])
<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.6.0._expand_conv
3
tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True, False,
         True,  True,  True,  True, False, False,  True,  True, False,  True,
         True,  True,  True, False,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True,  True,
        False,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True, False,  True,  True,  True, False,  True,  True, False,
         True,  True,  True,  True, False, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True,  True,  True,  True, False,  True, False,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True, False,  True,  True,  True, False,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True, False,  True,  True,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True,  True, False, False,  True,  True,
         True, False,  True,  True,  True,  True, False,  True, False,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False, False, False,  True,  True,  True, False, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True,  True,
         True, False,  True,  True,  True,  True,  True, False,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True, False,
         True,  True,  True, False,  True, False,  True,  True, False,  True,
         True,  True,  True,  True,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False,  True,
         True,  True,  True, False,  True, False,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True, False, False,
         True,  True,  True, False,  True,  True,  True,  True, False,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True,  True, False,  True,  True, False,  True,  True,  True,  True,
         True,  True, False,  True,  True,  True,  True,  True, False,  True,
         True, False,  True,  True,  True,  True,  True,  True,  True, False,
         True,  True, False,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True, False,  True,  True,  True,
         True, False,  True,  True,  True, False,  True, False,  True,  True,
         True,  True,  True,  True,  True,  True,  True, False, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True, False,  True,  True,  True,  True,  True,  True,
        False, False,  True,  True,  True,  True,  True, False, False,  True,
        False,  True,  True,  True, False, False, False,  True,  True,  True,
         True,  True, False, False,  True,  True,  True,  True,  True,  True,
         True, False, False,  True,  True, False, False,  True,  True,  True,
         True, False, False,  True,  True,  True,  True, False,  True,  True,
        False,  True,  True,  True,  True])
torch.Size([585])
torch.Size([476])
backbone.blocks.6.0._project_conv
0

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.blocks.6.0._project_conv (Conv2d(476, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.blocks.6.0._project_conv (Conv2d(476, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=0
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.blocks.6.0._project_conv
1
tensor([True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True, True, True, True, True,
        True, True, True, True, True, True, True, True])
torch.Size([320])
torch.Size([320])
Starting Training Cycle
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86       [1, 673, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88       [1, 673, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89       [1, 673, 5, 5]          16,825          16,825
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93       [1, 412, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95       [1, 412, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96       [1, 412, 5, 5]          10,300          10,300
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100       [1, 318, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102       [1, 318, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103       [1, 318, 5, 5]           7,950           7,950
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107       [1, 476, 5, 5]          91,392          91,392
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108       [1, 476, 5, 5]             952             952
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109       [1, 476, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110       [1, 476, 5, 5]           4,284           4,284
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111       [1, 476, 5, 5]             952             952
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         152,320         152,320
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114      [1, 1280, 5, 5]         409,600         409,600
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115      [1, 1280, 5, 5]           2,560           2,560
               RecycleNetwork/EfficientNetLite                ReLU6-116      [1, 1280, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117      [1, 1280, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118            [1, 1280]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]           6,405           6,405
============================================================================================================================
Total params: 1,897,117
Trainable params: 1,897,117
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Ended Training Cycle
backbone.head.0
1082

--------------------------------
          Pruning Group
--------------------------------
[0] prune_out_channels on backbone.head.0 (Conv2d(320, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.head.0 (Conv2d(320, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)), #idxs=1082
[1] prune_out_channels on backbone.head.0 (Conv2d(320, 198, kernel_size=(1, 1), stride=(1, 1), bias=False)) => prune_out_channels on backbone.head.1 (BatchNorm2d(198, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)), #idxs=1082
[2] prune_out_channels on backbone.head.1 (BatchNorm2d(198, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_3(HardtanhBackward0), #idxs=1082
[3] prune_out_channels on _ElementWiseOp_3(HardtanhBackward0) => prune_out_channels on _ElementWiseOp_2(MeanBackward1), #idxs=1082
[4] prune_out_channels on _ElementWiseOp_2(MeanBackward1) => prune_out_channels on _Reshape_0(), #idxs=1082
[5] prune_out_channels on _Reshape_0() => prune_in_channels on backbone.fc (Linear(in_features=198, out_features=5, bias=True)), #idxs=1082
[6] prune_in_channels on backbone.fc (Linear(in_features=198, out_features=5, bias=True)) => prune_out_channels on _ElementWiseOp_1(TBackward0), #idxs=1082
--------------------------------

<bound method ConvPruner.prune_out_channels of <torch_pruning.pruner.function.ConvPruner object at 0x7fcee44d1960>>
backbone.head.0
0
tensor([ True, False, False,  ..., False,  True, False])
torch.Size([1280])
torch.Size([198])
4967
----------------------------------------------------------------------------------------------------------------------------
                                 Parent Layers             Layer (type)         Output Shape         Param #     Tr. Param #
============================================================================================================================
               RecycleNetwork/EfficientNetLite                 Conv2d-1      [1, 27, 75, 75]             729             729
               RecycleNetwork/EfficientNetLite            BatchNorm2d-2      [1, 27, 75, 75]              54              54
               RecycleNetwork/EfficientNetLite                  ReLU6-3      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-4      [1, 27, 75, 75]             243             243
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-5      [1, 27, 75, 75]              54              54
   RecycleNetwork/EfficientNetLite/MBConvBlock                  ReLU6-6      [1, 27, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-7      [1, 16, 75, 75]             432             432
   RecycleNetwork/EfficientNetLite/MBConvBlock            BatchNorm2d-8      [1, 16, 75, 75]              32              32
   RecycleNetwork/EfficientNetLite/MBConvBlock                 Conv2d-9      [1, 89, 75, 75]           1,424           1,424
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-10      [1, 89, 75, 75]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-11      [1, 89, 75, 75]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-12      [1, 89, 38, 38]             801             801
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-13      [1, 89, 38, 38]             178             178
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-14      [1, 24, 38, 38]           2,136           2,136
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-15      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-16     [1, 129, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-17     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-18     [1, 129, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-19     [1, 129, 38, 38]           1,161           1,161
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-20     [1, 129, 38, 38]             258             258
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-21      [1, 24, 38, 38]           3,096           3,096
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-22      [1, 24, 38, 38]              48              48
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-23     [1, 139, 38, 38]           3,336           3,336
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-24     [1, 139, 38, 38]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-25     [1, 139, 38, 38]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-26     [1, 139, 19, 19]           3,475           3,475
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-27     [1, 139, 19, 19]             278             278
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-28      [1, 40, 19, 19]           5,560           5,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-29      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-30     [1, 201, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-31     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-32     [1, 201, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-33     [1, 201, 19, 19]           5,025           5,025
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-34     [1, 201, 19, 19]             402             402
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-35      [1, 40, 19, 19]           8,040           8,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-36      [1, 40, 19, 19]              80              80
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-37     [1, 232, 19, 19]           9,280           9,280
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-38     [1, 232, 19, 19]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-39     [1, 232, 19, 19]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-40     [1, 232, 10, 10]           2,088           2,088
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-41     [1, 232, 10, 10]             464             464
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-42      [1, 80, 10, 10]          18,560          18,560
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-43      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-44     [1, 363, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-45     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-46     [1, 363, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-47     [1, 363, 10, 10]           3,267           3,267
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-48     [1, 363, 10, 10]             726             726
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-49      [1, 80, 10, 10]          29,040          29,040
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-50      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-51     [1, 333, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-52     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-53     [1, 333, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-54     [1, 333, 10, 10]           2,997           2,997
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-55     [1, 333, 10, 10]             666             666
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-56      [1, 80, 10, 10]          26,640          26,640
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-57      [1, 80, 10, 10]             160             160
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-58     [1, 455, 10, 10]          36,400          36,400
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-59     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-60     [1, 455, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-61     [1, 455, 10, 10]          11,375          11,375
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-62     [1, 455, 10, 10]             910             910
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-63     [1, 112, 10, 10]          50,960          50,960
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-64     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-65     [1, 458, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-66     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-67     [1, 458, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-68     [1, 458, 10, 10]          11,450          11,450
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-69     [1, 458, 10, 10]             916             916
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-70     [1, 112, 10, 10]          51,296          51,296
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-71     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-72     [1, 343, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-73     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-74     [1, 343, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-75     [1, 343, 10, 10]           8,575           8,575
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-76     [1, 343, 10, 10]             686             686
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-77     [1, 112, 10, 10]          38,416          38,416
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-78     [1, 112, 10, 10]             224             224
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-79     [1, 427, 10, 10]          47,824          47,824
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-80     [1, 427, 10, 10]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-81     [1, 427, 10, 10]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-82       [1, 427, 5, 5]          10,675          10,675
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-83       [1, 427, 5, 5]             854             854
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-84       [1, 192, 5, 5]          81,984          81,984
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-85       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-86       [1, 673, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-87       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-88       [1, 673, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-89       [1, 673, 5, 5]          16,825          16,825
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-90       [1, 673, 5, 5]           1,346           1,346
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-91       [1, 192, 5, 5]         129,216         129,216
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-92       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-93       [1, 412, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-94       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                 ReLU6-95       [1, 412, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-96       [1, 412, 5, 5]          10,300          10,300
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-97       [1, 412, 5, 5]             824             824
   RecycleNetwork/EfficientNetLite/MBConvBlock                Conv2d-98       [1, 192, 5, 5]          79,104          79,104
   RecycleNetwork/EfficientNetLite/MBConvBlock           BatchNorm2d-99       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-100       [1, 318, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-101       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-102       [1, 318, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-103       [1, 318, 5, 5]           7,950           7,950
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-104       [1, 318, 5, 5]             636             636
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-105       [1, 192, 5, 5]          61,056          61,056
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-106       [1, 192, 5, 5]             384             384
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-107       [1, 476, 5, 5]          91,392          91,392
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-108       [1, 476, 5, 5]             952             952
   RecycleNetwork/EfficientNetLite/MBConvBlock                ReLU6-109       [1, 476, 5, 5]               0               0
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-110       [1, 476, 5, 5]           4,284           4,284
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-111       [1, 476, 5, 5]             952             952
   RecycleNetwork/EfficientNetLite/MBConvBlock               Conv2d-112       [1, 320, 5, 5]         152,320         152,320
   RecycleNetwork/EfficientNetLite/MBConvBlock          BatchNorm2d-113       [1, 320, 5, 5]             640             640
               RecycleNetwork/EfficientNetLite               Conv2d-114       [1, 198, 5, 5]          63,360          63,360
               RecycleNetwork/EfficientNetLite          BatchNorm2d-115       [1, 198, 5, 5]             396             396
               RecycleNetwork/EfficientNetLite                ReLU6-116       [1, 198, 5, 5]               0               0
               RecycleNetwork/EfficientNetLite    AdaptiveAvgPool2d-117       [1, 198, 1, 1]               0               0
               RecycleNetwork/EfficientNetLite              Dropout-118             [1, 198]               0               0
               RecycleNetwork/EfficientNetLite               Linear-119               [1, 5]             995             995
============================================================================================================================
Total params: 1,543,303
Trainable params: 1,543,303
Non-trainable params: 0
----------------------------------------------------------------------------------------------------------------------------
Training Started
Epoch: 1, Training Loss: 0.975056, Validation Loss: 0.928750, Training Accuracy: 0.586990, Validation Accuracy: 0.607470
Validation loss decreased (inf --> 0.928750).  Saving model ...
Epoch: 2, Training Loss: 0.947260, Validation Loss: 0.899492, Training Accuracy: 0.602988, Validation Accuracy: 0.626704
Validation loss decreased (0.928750 --> 0.899492).  Saving model ...
Epoch: 3, Training Loss: 0.919121, Validation Loss: 0.872742, Training Accuracy: 0.618238, Validation Accuracy: 0.645191
Validation loss decreased (0.899492 --> 0.872742).  Saving model ...
Epoch: 4, Training Loss: 0.895453, Validation Loss: 0.848458, Training Accuracy: 0.639340, Validation Accuracy: 0.664986
Validation loss decreased (0.872742 --> 0.848458).  Saving model ...
Epoch: 5, Training Loss: 0.875964, Validation Loss: 0.823153, Training Accuracy: 0.652101, Validation Accuracy: 0.681606
Validation loss decreased (0.848458 --> 0.823153).  Saving model ...
Epoch: 6, Training Loss: 0.851456, Validation Loss: 0.803752, Training Accuracy: 0.668410, Validation Accuracy: 0.696732
Validation loss decreased (0.823153 --> 0.803752).  Saving model ...
Epoch: 7, Training Loss: 0.828330, Validation Loss: 0.778106, Training Accuracy: 0.684220, Validation Accuracy: 0.708310
Validation loss decreased (0.803752 --> 0.778106).  Saving model ...
Epoch: 8, Training Loss: 0.806143, Validation Loss: 0.758741, Training Accuracy: 0.697541, Validation Accuracy: 0.719888
Validation loss decreased (0.778106 --> 0.758741).  Saving model ...
Epoch: 9, Training Loss: 0.790598, Validation Loss: 0.738847, Training Accuracy: 0.707999, Validation Accuracy: 0.724930
Validation loss decreased (0.758741 --> 0.738847).  Saving model ...
Epoch: 10, Training Loss: 0.774923, Validation Loss: 0.721780, Training Accuracy: 0.717398, Validation Accuracy: 0.733894
Validation loss decreased (0.738847 --> 0.721780).  Saving model ...
Epoch: 11, Training Loss: 0.755976, Validation Loss: 0.703341, Training Accuracy: 0.727793, Validation Accuracy: 0.741176
Validation loss decreased (0.721780 --> 0.703341).  Saving model ...
Epoch: 12, Training Loss: 0.739541, Validation Loss: 0.686708, Training Accuracy: 0.733956, Validation Accuracy: 0.746965
Validation loss decreased (0.703341 --> 0.686708).  Saving model ...
Epoch: 13, Training Loss: 0.724303, Validation Loss: 0.673718, Training Accuracy: 0.741923, Validation Accuracy: 0.755182
Validation loss decreased (0.686708 --> 0.673718).  Saving model ...
Epoch: 14, Training Loss: 0.712566, Validation Loss: 0.658962, Training Accuracy: 0.747899, Validation Accuracy: 0.767507
Validation loss decreased (0.673718 --> 0.658962).  Saving model ...
Epoch: 15, Training Loss: 0.695256, Validation Loss: 0.643679, Training Accuracy: 0.756489, Validation Accuracy: 0.778525
Validation loss decreased (0.658962 --> 0.643679).  Saving model ...
Epoch: 16, Training Loss: 0.683334, Validation Loss: 0.629878, Training Accuracy: 0.763772, Validation Accuracy: 0.786741
Validation loss decreased (0.643679 --> 0.629878).  Saving model ...
Epoch: 17, Training Loss: 0.668058, Validation Loss: 0.617645, Training Accuracy: 0.773358, Validation Accuracy: 0.799813
Validation loss decreased (0.629878 --> 0.617645).  Saving model ...
Epoch: 18, Training Loss: 0.658624, Validation Loss: 0.606323, Training Accuracy: 0.782197, Validation Accuracy: 0.809337
Validation loss decreased (0.617645 --> 0.606323).  Saving model ...
Epoch: 19, Training Loss: 0.651304, Validation Loss: 0.591230, Training Accuracy: 0.787862, Validation Accuracy: 0.820355
Validation loss decreased (0.606323 --> 0.591230).  Saving model ...
Epoch: 20, Training Loss: 0.633336, Validation Loss: 0.580281, Training Accuracy: 0.797137, Validation Accuracy: 0.828198
Validation loss decreased (0.591230 --> 0.580281).  Saving model ...
Epoch: 21, Training Loss: 0.625123, Validation Loss: 0.570760, Training Accuracy: 0.800996, Validation Accuracy: 0.841830
Validation loss decreased (0.580281 --> 0.570760).  Saving model ...
Epoch: 22, Training Loss: 0.614722, Validation Loss: 0.559232, Training Accuracy: 0.810084, Validation Accuracy: 0.845005
Validation loss decreased (0.570760 --> 0.559232).  Saving model ...
Epoch: 23, Training Loss: 0.608461, Validation Loss: 0.549526, Training Accuracy: 0.814877, Validation Accuracy: 0.851354
Validation loss decreased (0.559232 --> 0.549526).  Saving model ...
Epoch: 24, Training Loss: 0.593345, Validation Loss: 0.539961, Training Accuracy: 0.826019, Validation Accuracy: 0.856583
Validation loss decreased (0.549526 --> 0.539961).  Saving model ...
Epoch: 25, Training Loss: 0.587680, Validation Loss: 0.532051, Training Accuracy: 0.826891, Validation Accuracy: 0.860691
Validation loss decreased (0.539961 --> 0.532051).  Saving model ...
Epoch: 26, Training Loss: 0.578364, Validation Loss: 0.521755, Training Accuracy: 0.835294, Validation Accuracy: 0.862185
Validation loss decreased (0.532051 --> 0.521755).  Saving model ...
Epoch: 27, Training Loss: 0.567257, Validation Loss: 0.513619, Training Accuracy: 0.837908, Validation Accuracy: 0.867787
Validation loss decreased (0.521755 --> 0.513619).  Saving model ...
Epoch: 28, Training Loss: 0.558626, Validation Loss: 0.503026, Training Accuracy: 0.845814, Validation Accuracy: 0.870215
Validation loss decreased (0.513619 --> 0.503026).  Saving model ...
Epoch: 29, Training Loss: 0.548613, Validation Loss: 0.496934, Training Accuracy: 0.848428, Validation Accuracy: 0.874136
Validation loss decreased (0.503026 --> 0.496934).  Saving model ...
Epoch: 30, Training Loss: 0.542633, Validation Loss: 0.490525, Training Accuracy: 0.854653, Validation Accuracy: 0.877684
Validation loss decreased (0.496934 --> 0.490525).  Saving model ...
Epoch: 31, Training Loss: 0.532653, Validation Loss: 0.481537, Training Accuracy: 0.856832, Validation Accuracy: 0.878431
Validation loss decreased (0.490525 --> 0.481537).  Saving model ...
Epoch: 32, Training Loss: 0.530509, Validation Loss: 0.472834, Training Accuracy: 0.859633, Validation Accuracy: 0.882166
Validation loss decreased (0.481537 --> 0.472834).  Saving model ...
Epoch: 33, Training Loss: 0.521496, Validation Loss: 0.467130, Training Accuracy: 0.861998, Validation Accuracy: 0.884781
Validation loss decreased (0.472834 --> 0.467130).  Saving model ...
Epoch: 34, Training Loss: 0.510821, Validation Loss: 0.458938, Training Accuracy: 0.866729, Validation Accuracy: 0.887582
Validation loss decreased (0.467130 --> 0.458938).  Saving model ...
Epoch: 35, Training Loss: 0.505969, Validation Loss: 0.451189, Training Accuracy: 0.871335, Validation Accuracy: 0.893371
Validation loss decreased (0.458938 --> 0.451189).  Saving model ...
Epoch: 36, Training Loss: 0.497330, Validation Loss: 0.445191, Training Accuracy: 0.873576, Validation Accuracy: 0.891877
Validation loss decreased (0.451189 --> 0.445191).  Saving model ...
Epoch: 37, Training Loss: 0.498559, Validation Loss: 0.437126, Training Accuracy: 0.873576, Validation Accuracy: 0.893184
Validation loss decreased (0.445191 --> 0.437126).  Saving model ...
Epoch: 38, Training Loss: 0.492142, Validation Loss: 0.433812, Training Accuracy: 0.876315, Validation Accuracy: 0.894304
Validation loss decreased (0.437126 --> 0.433812).  Saving model ...
Epoch: 39, Training Loss: 0.485158, Validation Loss: 0.425747, Training Accuracy: 0.873950, Validation Accuracy: 0.896919
Validation loss decreased (0.433812 --> 0.425747).  Saving model ...
Epoch: 40, Training Loss: 0.482750, Validation Loss: 0.420481, Training Accuracy: 0.877560, Validation Accuracy: 0.897292
Validation loss decreased (0.425747 --> 0.420481).  Saving model ...
Epoch: 41, Training Loss: 0.472294, Validation Loss: 0.413767, Training Accuracy: 0.883473, Validation Accuracy: 0.898786
Validation loss decreased (0.420481 --> 0.413767).  Saving model ...
Epoch: 42, Training Loss: 0.469579, Validation Loss: 0.407829, Training Accuracy: 0.885652, Validation Accuracy: 0.898973
Validation loss decreased (0.413767 --> 0.407829).  Saving model ...
Epoch: 43, Training Loss: 0.459651, Validation Loss: 0.404651, Training Accuracy: 0.885777, Validation Accuracy: 0.901401
Validation loss decreased (0.407829 --> 0.404651).  Saving model ...
Epoch: 44, Training Loss: 0.462803, Validation Loss: 0.396886, Training Accuracy: 0.883100, Validation Accuracy: 0.901961
Validation loss decreased (0.404651 --> 0.396886).  Saving model ...
Epoch: 45, Training Loss: 0.453812, Validation Loss: 0.391348, Training Accuracy: 0.886275, Validation Accuracy: 0.904015
Validation loss decreased (0.396886 --> 0.391348).  Saving model ...
Epoch: 46, Training Loss: 0.451105, Validation Loss: 0.387691, Training Accuracy: 0.887582, Validation Accuracy: 0.903081
Validation loss decreased (0.391348 --> 0.387691).  Saving model ...
Epoch: 47, Training Loss: 0.442151, Validation Loss: 0.381160, Training Accuracy: 0.891379, Validation Accuracy: 0.902894
Validation loss decreased (0.387691 --> 0.381160).  Saving model ...
Epoch: 48, Training Loss: 0.433583, Validation Loss: 0.376865, Training Accuracy: 0.891566, Validation Accuracy: 0.905322
Validation loss decreased (0.381160 --> 0.376865).  Saving model ...
Epoch: 49, Training Loss: 0.432566, Validation Loss: 0.373072, Training Accuracy: 0.894118, Validation Accuracy: 0.904388
Validation loss decreased (0.376865 --> 0.373072).  Saving model ...
Epoch: 50, Training Loss: 0.427925, Validation Loss: 0.368933, Training Accuracy: 0.895425, Validation Accuracy: 0.906443
Validation loss decreased (0.373072 --> 0.368933).  Saving model ...
Epoch: 51, Training Loss: 0.423245, Validation Loss: 0.366133, Training Accuracy: 0.897417, Validation Accuracy: 0.906816
Validation loss decreased (0.368933 --> 0.366133).  Saving model ...
Epoch: 52, Training Loss: 0.416869, Validation Loss: 0.362258, Training Accuracy: 0.898724, Validation Accuracy: 0.908310
Validation loss decreased (0.366133 --> 0.362258).  Saving model ...
Epoch: 53, Training Loss: 0.413541, Validation Loss: 0.357095, Training Accuracy: 0.898226, Validation Accuracy: 0.910177
Validation loss decreased (0.362258 --> 0.357095).  Saving model ...
Epoch: 54, Training Loss: 0.408640, Validation Loss: 0.353976, Training Accuracy: 0.900467, Validation Accuracy: 0.909617
Validation loss decreased (0.357095 --> 0.353976).  Saving model ...
Epoch: 55, Training Loss: 0.406712, Validation Loss: 0.349664, Training Accuracy: 0.898537, Validation Accuracy: 0.910177
Validation loss decreased (0.353976 --> 0.349664).  Saving model ...
Epoch: 56, Training Loss: 0.404079, Validation Loss: 0.346880, Training Accuracy: 0.901027, Validation Accuracy: 0.912045
Validation loss decreased (0.349664 --> 0.346880).  Saving model ...
Epoch: 57, Training Loss: 0.403488, Validation Loss: 0.342541, Training Accuracy: 0.900218, Validation Accuracy: 0.911111
Validation loss decreased (0.346880 --> 0.342541).  Saving model ...
Epoch: 58, Training Loss: 0.399117, Validation Loss: 0.340335, Training Accuracy: 0.901401, Validation Accuracy: 0.914099
Validation loss decreased (0.342541 --> 0.340335).  Saving model ...
Epoch: 59, Training Loss: 0.397487, Validation Loss: 0.336043, Training Accuracy: 0.901027, Validation Accuracy: 0.914099
Validation loss decreased (0.340335 --> 0.336043).  Saving model ...
Epoch: 60, Training Loss: 0.390396, Validation Loss: 0.335580, Training Accuracy: 0.902334, Validation Accuracy: 0.914846
Validation loss decreased (0.336043 --> 0.335580).  Saving model ...
Epoch: 61, Training Loss: 0.383593, Validation Loss: 0.332499, Training Accuracy: 0.904264, Validation Accuracy: 0.913352
Validation loss decreased (0.335580 --> 0.332499).  Saving model ...
Epoch: 62, Training Loss: 0.385198, Validation Loss: 0.328383, Training Accuracy: 0.905011, Validation Accuracy: 0.915780
Validation loss decreased (0.332499 --> 0.328383).  Saving model ...
Epoch: 63, Training Loss: 0.375923, Validation Loss: 0.328860, Training Accuracy: 0.908746, Validation Accuracy: 0.914846
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
EarlyStopping counter: 1 out of 10
Epoch: 64, Training Loss: 0.380179, Validation Loss: 0.320742, Training Accuracy: 0.906443, Validation Accuracy: 0.916900
Validation loss decreased (0.328383 --> 0.320742).  Saving model ...
Epoch: 65, Training Loss: 0.380136, Validation Loss: 0.324493, Training Accuracy: 0.905509, Validation Accuracy: 0.917274
EarlyStopping counter: 1 out of 10
Epoch: 66, Training Loss: 0.382040, Validation Loss: 0.323500, Training Accuracy: 0.904513, Validation Accuracy: 0.917274
EarlyStopping counter: 2 out of 10
Epoch: 67, Training Loss: 0.376232, Validation Loss: 0.322087, Training Accuracy: 0.905882, Validation Accuracy: 0.915966
EarlyStopping counter: 3 out of 10
Epoch: 68, Training Loss: 0.383613, Validation Loss: 0.322763, Training Accuracy: 0.902023, Validation Accuracy: 0.916900
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
EarlyStopping counter: 4 out of 10
Epoch: 69, Training Loss: 0.378328, Validation Loss: 0.321009, Training Accuracy: 0.906069, Validation Accuracy: 0.917274
EarlyStopping counter: 5 out of 10
Epoch: 70, Training Loss: 0.379593, Validation Loss: 0.323132, Training Accuracy: 0.904513, Validation Accuracy: 0.916713
EarlyStopping counter: 6 out of 10
Epoch: 71, Training Loss: 0.376289, Validation Loss: 0.323406, Training Accuracy: 0.904824, Validation Accuracy: 0.914846
EarlyStopping counter: 7 out of 10
Epoch: 72, Training Loss: 0.374036, Validation Loss: 0.321712, Training Accuracy: 0.908808, Validation Accuracy: 0.916153
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
EarlyStopping counter: 8 out of 10
Epoch: 73, Training Loss: 0.379077, Validation Loss: 0.324309, Training Accuracy: 0.905758, Validation Accuracy: 0.916900
EarlyStopping counter: 9 out of 10
Epoch: 74, Training Loss: 0.382283, Validation Loss: 0.321494, Training Accuracy: 0.904700, Validation Accuracy: 0.916340
EarlyStopping counter: 10 out of 10
Early Stopping at Epoch: 74
Test Loss: 0.313790, Test Accuracy: 0.9193
